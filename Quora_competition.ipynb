{
  "cells": [
    {
      "metadata": {
        "_uuid": "9f8d043cdaae45df19c6993f0e04897fa88fbfc9"
      },
      "cell_type": "markdown",
      "source": "# Quora insincere questions"
    },
    {
      "metadata": {
        "_uuid": "67b686f96821b15891a6f27a45b3e29ee36b9d4a"
      },
      "cell_type": "markdown",
      "source": "### Objective of the competition : predict if a question is insincere (1) or not (0) to help the moderation system of Quora. \n**Parameters to evaluate the insincerity:**\n* non-neutral tone (exagerated or rhetorical)\n* disparaging or inflamatory questions (suggest discriminatory idea, hateful, based on prejudices)\n* not grounded in reality (absurd or false)\n* sexual content for shock value + illicite sexual content"
    },
    {
      "metadata": {
        "_uuid": "f1222da4c522678f79e0e29b29bb8db2d43d4007"
      },
      "cell_type": "markdown",
      "source": "I'm new to machine learning so i began by doing a topic modeling with gensim to see if i can identify recurent topics differencing sincere and insincere question.\n\nThe machine learning part is a more concise cause i wanted to focus on topic modeling. "
    },
    {
      "metadata": {
        "_uuid": "b3e771a30125f304f8cde60f9966326fe4b3ff17"
      },
      "cell_type": "markdown",
      "source": "# I. Imports and loading the data"
    },
    {
      "metadata": {
        "_uuid": "577a8fe33d17fcea54a0ec894bcbaf330daa614c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2e5700fd6179086268b1e14b8ca5a3b8ea4f86b2",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#from vivadata.datasets.common import get_path_for_dataset\n#base_path = get_path_for_dataset('quora')\nX_train_filepath = os.path.join('..', 'input', 'train.csv')\nX_test_filepath = os.path.join('..', 'input', 'test.csv')\nsample_filepath = os.path.join('..', 'input', 'sample_submission.csv')\nX_train_filepath, X_test_filepath, sample_filepath",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0b7358f5b361b068c1599bdb279da32d95819e68",
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_train = pd.read_csv(X_train_filepath)\ndf_test = pd.read_csv(X_test_filepath)\nsample = pd.read_csv(sample_filepath)\ndf_train.shape, df_test.shape, sample.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "79a4101d4cdbdbb5a971b413e0f7eaeb6eece0fb"
      },
      "cell_type": "markdown",
      "source": "Now that the data is loaded, let's take a quick look. \n![](https://media.giphy.com/media/94hqi5hBHu5W/giphy.gif)"
    },
    {
      "metadata": {
        "_uuid": "5ee5841bcb36c99667bae629b4003cc794c32d15"
      },
      "cell_type": "markdown",
      "source": "#  II.EDA"
    },
    {
      "metadata": {
        "_uuid": "501206bff3ac1dffebab97152a3fe0afda23c790",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "df_train.sample(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c6df2de49f99794c190e045a3f38f5c214992710"
      },
      "cell_type": "markdown",
      "source": "- **qid** = unique question identifier\n- **question_text** = text of the question\n- **target** = 1: insincere question, 0:not insincere question"
    },
    {
      "metadata": {
        "_uuid": "2b29963e5eb52e85d83dbd9237843e3d1b208a78",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_test.sample(10)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d3f7bf37785af749359209cb18bbd5ca240a3271"
      },
      "cell_type": "markdown",
      "source": "**qid** = unique question identifier\n**question_text** = text of the question"
    },
    {
      "metadata": {
        "_uuid": "4032f753b58f5eb4ee1189d5ea79302141de19dd",
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_train.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1e5c2307fef25939036b586432009eb9d8da2b4d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "df_train.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7da2279d132afba499ca994360c2421188446407",
        "trusted": true
      },
      "cell_type": "code",
      "source": "ax, fig = plt.subplots(figsize=(10, 7))\nsns.countplot(x='target', data=df_train)\nplt.title('Reparition of question by insincerity');",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "663b61c6f71fcb951fc9f63d7b600253205cd9db"
      },
      "cell_type": "markdown",
      "source": "There is 80 810 insincere questions on 1 306 122, so around 6% (0.0618). This would be a problem for the machin learning process cause it's an important disparity with 1 225 312 sincere ones. "
    },
    {
      "metadata": {
        "_uuid": "a36adf7ade1ba2427a7ceb518be2eac3c3b46b9a"
      },
      "cell_type": "markdown",
      "source": "**_Now, we need to transform the data from text to something the computer could understand in order to study it more precisely._**"
    },
    {
      "metadata": {
        "_uuid": "e556d7a2327e43a2acabfc125684edbaaae4a403"
      },
      "cell_type": "markdown",
      "source": "# III.Topic modelisation"
    },
    {
      "metadata": {
        "_uuid": "d8c1af96d3f57eafbd5591b2d75165e489f8e923"
      },
      "cell_type": "markdown",
      "source": "I'm gonna prepare the data,  then use gensim and lda modeling to create topics for sincere and insincere questions. "
    },
    {
      "metadata": {
        "_uuid": "4652a1c388aa3a8c8d8c91dc36a3451f33bad00f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import gensim\nimport nltk\nfrom nltk.corpus import stopwords",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b83a3c1f52bb59188bf5872e9657170594f38ed0",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Define the target and the variable.\ny_train = df_train.loc[:, 'target']\nX_train = df_train.loc[:, 'question_text']\nX_train.shape, y_train.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "157c4d713f540ced023046b8b096aca17767a8c0",
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c4a087f1198e4394d1a79eb3974d1a036a783eea",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create a variable with all the sincere questions.\nX_train_sincere = X_train[df_train['target'] == 0]\nX_train_sincere[:5]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fd1d2b1742345340428b655f7af9ddb5b316c0ec",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create a variable with all insincere questions.\nX_train_insincere = X_train[df_train['target'] == 1]\nX_train_insincere[:5]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "914b3cc960bb6608df0233c24ceae86b26440770"
      },
      "cell_type": "markdown",
      "source": "## III-A. Topic modeling with 10 topics"
    },
    {
      "metadata": {
        "_uuid": "0999d94e0bec5352a3201f39a25da7ac2edcf2d7"
      },
      "cell_type": "markdown",
      "source": "### III-A. 1. Tokenisation"
    },
    {
      "metadata": {
        "_uuid": "115305e95e861f1038833d578dade91aa4c29151"
      },
      "cell_type": "markdown",
      "source": "We need to transform the text data in token to be able to compute it. "
    },
    {
      "metadata": {
        "_uuid": "f9c149e7adee6b4edeec9fe6f88ee34432733cf2",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# First i load the list of stopwords, the words which aren't useful to understand the meaning.\nstop_words = stopwords.words('english')\nstop_words[:10]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "20b79966634510ca2de90a0507c92e908626833b",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# I transform the sincere questions in a list of words.\nsincere_prepro_questions = [gensim.utils.simple_preprocess(question) \n                            for question in X_train_sincere]\nsincere_prepro_questions[:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cac7c930067848b035ba4bd0ffecd91bc2236667",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# I transform the insincere questions in a list of words.\ninsincere_prepro_questions = [gensim.utils.simple_preprocess(question) \n                              for question in X_train_insincere]\ninsincere_prepro_questions[:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f6bccf903b7db840a6946ba9be130cc640d1a0c4",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Verifying the length of the both lists.\nlen(sincere_prepro_questions), len(insincere_prepro_questions)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "47bb008071e10b6f0cbb0bb79b1ff23c0ed5ab3f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# I remove the stopwords from the sincere questions list of words.\nclear_sincere_questions = [[word for word in question if word not in stop_words] \n                             for question in sincere_prepro_questions]\nclear_sincere_questions[:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0cd2135f9bf8c56224e80d1f954bc6db29506691",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# I do the same for insincere one.\nclear_insincere_questions = [[word for word in question if word not in stop_words] \n                             for question in insincere_prepro_questions]\nclear_insincere_questions[:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2c6fc8c66f22064970372aa26df1ea4aa93c4eb2"
      },
      "cell_type": "markdown",
      "source": "### III-A.2. Creation of gensim dictionnaries"
    },
    {
      "metadata": {
        "_uuid": "975ad3662530be084a500edeac33ffa4d3cdc506",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Creation of a dictionnary of the words and their id for sincere questions\nsincere_questions_dictionary = gensim.corpora.Dictionary(clear_sincere_questions)\nsincere_token = sincere_questions_dictionary.token2id",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "12d1ee97d13307701bc352fa0c97eef3650d8a9e",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Association of the dictonary words and their frequency for sincere questions\nsincere_dict_frequency = {sincere_questions_dictionary[k]: v for k,v in sincere_questions_dictionary.dfs.items()}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "87e11d7abf983d0f8edc396926dfbbd5ba3f3f40",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Creation of a dictionnary of the words and their id for insincere questions\ninsincere_questions_dictionary = gensim.corpora.Dictionary(clear_insincere_questions)\nsincere_token = sincere_questions_dictionary.token2id",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c207320d9210d9831b949aaa953fed9bb403590b",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Association of the dictonary words and their frequency for insincere questions\nsincere_dict_frequency = {sincere_questions_dictionary[k]: v for k,v in sincere_questions_dictionary.dfs.items()}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fd019436f022eaefd05ecb321add84b895f4f787"
      },
      "cell_type": "markdown",
      "source": "### III-A.3. Vectorization"
    },
    {
      "metadata": {
        "_uuid": "7946402dc8bc6163c8e6f5febba1ca6a822a040c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# I transform the elements of the sincere dictionary in vectors. \nsincere_corpus = [sincere_questions_dictionary.doc2bow(question) \n                  for question in clear_sincere_questions]\nsincere_corpus[:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "80e1b12bfda53e1fe576b1cdc15c308cec5605d4",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# I do the same for the insincere questions. \ninsincere_corpus = [insincere_questions_dictionary.doc2bow(question) \n                    for question in clear_insincere_questions]\ninsincere_corpus[:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8494cc3162710b5ff8f8854922ee47a15ffa2f5e"
      },
      "cell_type": "markdown",
      "source": "### III-A.4. Lda Modeling"
    },
    {
      "metadata": {
        "_uuid": "b8db83be80027f90fac5bfda44c56cc8aa1b39fd"
      },
      "cell_type": "markdown",
      "source": "Lda modeling is a statistical modeling which discovers abstract \"topics\" in documents. Here Lda modeling will help me to see if sincere and insincere questions have some majors topics. \n\nThis topics could be used as a variable later, for the machine learning."
    },
    {
      "metadata": {
        "_uuid": "7512625e7742c9fea90e22467535bbbf8dc858dd",
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Creating a lda model, which create 10 topics from the sincere questions\nlda_model_sincere = gensim.models.ldamodel.LdaModel(\n    corpus=sincere_corpus, num_topics=10, id2word=sincere_questions_dictionary,\n    random_state=25, passes=5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "48c57666ba81ea5e43c7e23806bc10fc0ec4c747",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Creating a lda model, which create 10 topics from the insincere questions\nlda_model_insincere = gensim.models.ldamodel.LdaModel(\n    corpus=insincere_corpus, num_topics=10, id2word=insincere_questions_dictionary,\n    random_state=25, passes=5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4fbecf59674ac58d475b378753165e74110fdad8",
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pprint import pprint",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d8027790e4cd246ca563da6b042a435ad6162a31",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Printing the result of the modeling for sincere questions.\npprint(lda_model_sincere.print_topics())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d2fcf8b751e48b29fa8edea9b3d215b9059b2db4",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Same for insincere ones. \npprint(lda_model_insincere.print_topics())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d2d1be01809367bf8177af4acae6e344d655c307"
      },
      "cell_type": "markdown",
      "source": "### III-A.5. Visualization\n\nI will now measure how good the topic modeling is and create a visual of the topics. \n\nMeasurement of how good a topic model is. \n* Coherence score : \n    * intrinsic measure: compare a word with the preceding & sucseeding ones. Calculate a log probability\n    * extrinsic measure: every single word is paired with every others. Use pointwise mutual information. "
    },
    {
      "metadata": {
        "_uuid": "620b9008db74b11971fe3e30decfc42c3c5a2696",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pyLDAvis.gensim\npyLDAvis.enable_notebook()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ab8ceeffd47484137210d821caae8c8463e0350e",
        "trusted": true
      },
      "cell_type": "code",
      "source": "pyLDAvis.gensim.prepare(lda_model_sincere, sincere_corpus, sincere_questions_dictionary)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7f071f77b707bb2e7416997856a1c8122afabfac"
      },
      "cell_type": "markdown",
      "source": "Some topics overlapt each other (1 &4, 9&7, 2&3). The topic are less easily recognizable than for insincere questions. We can \nrecognize word showing interogation, some vocabulary about computer... but the vocabulary is larger and more miscellaneous. "
    },
    {
      "metadata": {
        "_uuid": "5d9eae1cebca57474211cac2f7b52a62d3b772ed",
        "trusted": true
      },
      "cell_type": "code",
      "source": "pyLDAvis.gensim.prepare(lda_model_insincere, insincere_corpus, \n                        insincere_questions_dictionary)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ee31e751e2fc59907b736c9d822519afaab0687b"
      },
      "cell_type": "markdown",
      "source": "The number of topics are not optimal, we can see that some topics (1, 3, 7 and 2, 5) overlapt. Maybe those subjects could\ncould have be reunited in a same topics. \n\nThe 1, 3, 7 seems to be about politic:\n    * the first about Donald Trump;\n    * the third about international politic;\n    * the seventh about political parties. \n We also see that the 30 most relevant words are sometimes repeated in the 3 topics ('trump', 'liberals', 'president', 'supporters'). \n\nThe 2, 5 topics seems to be about racial and religious subject:\n    * the second refers to race ('white', 'black', 'chinese');\n    * and the second seems to be about Islam ('muslims', 'muslim', 'pakistant'). \n   \nTopics 8 and 6, even if they are not close to the 1st cluster contain a lot of similar words and seems to also be about politics:\n       * the 8th about Donald Trump's election also ('trump', 'president', 'obama')\n       * the 6th about interior politic and social subjects ('gun', 'clinton', 'rape')\n       \nThe 9th topic is about religion ('jews', 'christians', 'atheist')\n\nThe 10th and 4th seems to be about sex and gender:\n    * the 4th more about sex ('girl', 'sex', 'sexual');\n    * the 10th is less easy to classify but seems to be more about gender ('girl', 'gender', 'bible')\n\nAll those subjects has in common to be really polemics and suitable to trolls. This criteria would be easily used by a human \ncontrol but we need to find how to train your model to try to recognize it. \n\nThe insincere questions seems easier to distinct than the sincere ones, cause they are centred on a less various spectrum of words. "
    },
    {
      "metadata": {
        "_uuid": "c5827b3999ddf9ff1934de5358fc4d5e4b7b2b91"
      },
      "cell_type": "markdown",
      "source": "---"
    },
    {
      "metadata": {
        "_uuid": "ca1170b3ffd04161bb5716c77ecdee6ea4c1745f"
      },
      "cell_type": "markdown",
      "source": "**Now we do the same process with bigrams!**!"
    },
    {
      "metadata": {
        "_uuid": "ab3b8eea4b67733a0f540a97e1a653e05360111c"
      },
      "cell_type": "markdown",
      "source": "## III-B. Topics modeling with bigrams (10 topics)"
    },
    {
      "metadata": {
        "_uuid": "ec22df4b463eb479fd2063f668ad9f57cb6fc327"
      },
      "cell_type": "markdown",
      "source": "### III-B.1. Creation of the bigrams (from preprocessed data)"
    },
    {
      "metadata": {
        "_uuid": "7d4113dbc53d9cd685edb53a319c2ac80220be7e",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from gensim.models import Phrases\nfrom gensim.models.phrases import Phraser",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "18776ed18ed023493e3944f525f0742107fbc06d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create the bigram for sincere questions.\nsincere_bigram_model = Phrases(sincere_prepro_questions, min_count=1, threshold=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7c79d824ab235a5ce21d261ff16a1497026cc334",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Same for insincere ones. \ninsincere_bigram_model = Phrases(insincere_prepro_questions, min_count=1, threshold=2)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cbaa02d7e15e4d6f06afd6a10605203c5dc84681",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Creation of the phrasers, which is needed to use the bigrams. First for sincere questions...\nsincere_bigram_phraser = Phraser(sincere_bigram_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "10324baec7fedd4f956f56207d0a3fc3b157d6f2",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Then for the insincere. \ninsincere_bigram_phraser = Phraser(sincere_bigram_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8bee51b6678ca254bef378d58c54e256826cef0f"
      },
      "cell_type": "markdown",
      "source": "### III-B.2.Creation of the bigram dictionary"
    },
    {
      "metadata": {
        "_uuid": "c73ab5f0828ea80fd303c5f9a11d5a6015c8f5f0",
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "sincere_bigrams = [sincere_bigram_model[question] for question in sincere_prepro_questions]\nsincere_bigrams[:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3fb510db651dae94b5e3963dc4b23580d2485247",
        "trusted": true
      },
      "cell_type": "code",
      "source": "insincere_bigrams = [insincere_bigram_model[question] for question in insincere_prepro_questions]\ninsincere_bigrams[:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b42bc729a87eb4ff37925ab24a43e276ee60743c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Creation of a dictionary with the words and their id for sincere bigrams\nsincere_bigrams_dictionary = gensim.corpora.Dictionary(sincere_bigrams)\nsincere_bigrams_token = sincere_bigrams_dictionary.token2id",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2d9e4a17a6302b615b0bf1874eb36fc50acd28c6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Association of the dictonary words and their frequency for sincere bigrams\nsincere_bigrams_frequency = {sincere_bigrams_dictionary[k]: \n                             v for k,v in sincere_bigrams_dictionary.dfs.items()}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "72787ff0db0649d335fd749066c05a044149d892",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Creation of a dictionary with the words and their id for insincere bigrams\ninsincere_bigrams_dictionary = gensim.corpora.Dictionary(insincere_bigrams)\ninsincere_bigrams_token = insincere_bigrams_dictionary.token2id",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "68825eeda0e1e6270bc8ba55f480c227a9110116",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Association of the dictonary words and their frequency for insincere bigrams\ninsincere_bigrams_frequency = {insincere_bigrams_dictionary[k]: \n                               v for k,v in insincere_bigrams_dictionary.dfs.items()}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "545652d2cf6e6333f368fc3dce9271495d7b7610"
      },
      "cell_type": "markdown",
      "source": "### III-B.3. Vectorization"
    },
    {
      "metadata": {
        "_uuid": "fb890995d2d48ac0f9e66a49f57cdc477d5fd354",
        "trusted": true
      },
      "cell_type": "code",
      "source": "sincere_bigrams_corpus = [sincere_bigrams_dictionary.doc2bow(question) \n                  for question in clear_sincere_questions]\nsincere_bigrams_corpus[:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "92ec5a1b67271360f884ee282a3d9bf6ed61db42",
        "trusted": true
      },
      "cell_type": "code",
      "source": "insincere_bigrams_corpus = [insincere_bigrams_dictionary.doc2bow(question) \n                  for question in clear_insincere_questions]\ninsincere_bigrams_corpus[:2]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5cdb535fdc30d17b73bc13f79659186fd86f2fc7"
      },
      "cell_type": "markdown",
      "source": " ### III-B.4. Lda Modeling"
    },
    {
      "metadata": {
        "_uuid": "34e995fa804764ce7afd43d78f16bd8a12a13de6",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Creating a lda model, which create 10 topics from the sincere bigrams\nlda_model_sincere_bigrams = gensim.models.ldamodel.LdaModel(\n    corpus=sincere_bigrams_corpus, num_topics=10, id2word=sincere_bigrams_dictionary,\n    random_state=25, passes=5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7cafcaf4fc454c958531d22f3a51ff3613c9c05f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Creating a lda model, which create 10 topics from the insincere bigrams\nimport warnings\nwarnings.filterwarnings('ignore')\n\nlda_model_insincere_bigrams = gensim.models.ldamodel.LdaModel(\n    corpus=insincere_bigrams_corpus, num_topics=10, id2word=insincere_bigrams_dictionary,\n    random_state=25, passes=5)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e58bbc1a3b17089860a2b74db6124c2160b903fd",
        "trusted": true
      },
      "cell_type": "code",
      "source": "pprint(lda_model_sincere_bigrams.print_topics())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4a902fc33b9a25a17f894868c4f536264e3f8d52",
        "trusted": true
      },
      "cell_type": "code",
      "source": "pprint(lda_model_insincere_bigrams.print_topics())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2894db30bd4ec4a4f0cb111cb903f2105b7802b2"
      },
      "cell_type": "markdown",
      "source": "### III-B.5. Computing cohenrence and visualization"
    },
    {
      "metadata": {
        "_uuid": "4b77e4d696f22e5a1848ff856b022187e63c8973",
        "trusted": true
      },
      "cell_type": "code",
      "source": "coherence_lda_model_sincere_b = CoherenceModel(\n    model=lda_model_sincere_bigrams, texts=clear_sincere_questions, \n    dictionary=sincere_bigrams_dictionary, coherence='c_v')\n\ncoherence_lda_3 = coherence_lda_model_sincere_b.get_coherence()\ncoherence_lda_3",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d7921a83394527b1b2448b3edcc885fa463f6b41",
        "scrolled": false,
        "trusted": true
      },
      "cell_type": "code",
      "source": "pyLDAvis.gensim.prepare(lda_model_sincere_bigrams, sincere_bigrams_corpus, \n                        sincere_bigrams_dictionary)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e8c402bd109dca9fbb6902c628d3d535422d58fe"
      },
      "cell_type": "markdown",
      "source": "Even if the graph shows unique word, the circles take into account the bigrams. \n\nThe repartition of the topics is quite different and some emerge more clearly. \n\nThe first topic, which is one of the 2 biggest, seems to be about education and job. \n\nThe 2nd one, which is also quite big, gather word indicating interrogation. It seems to be less a topic and more markers of real question (opposed to affirmation disguise in question)\n\nThe others topics are more mixed and once again some of them overlap each other, indicating that 10 topics is probably too much. Some secondary subjects appears but they're not as recognizable as insincere questions. \n"
    },
    {
      "metadata": {
        "_uuid": "51346c0c7fa28600c128dcbbd54e3660083b38c1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "coherence_lda_model_insincere_b = CoherenceModel(\n    model=lda_model_insincere_bigrams, texts=clear_insincere_questions, \n    dictionary=insincere_bigrams_dictionary, coherence='c_v')\n\ncoherence_lda_4 = coherence_lda_model_insincere_b.get_coherence()\ncoherence_lda_4",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "72fd76e2b5b16d65c04f6fd738eec8ee801356ed",
        "trusted": true
      },
      "cell_type": "code",
      "source": "pyLDAvis.gensim.prepare(lda_model_insincere_bigrams, insincere_bigrams_corpus, \n                        insincere_bigrams_dictionary)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "88bade77990dfeaa1e70b2965962a90a0ffa7155"
      },
      "cell_type": "markdown",
      "source": "The result are quite similar to the first one. Even if some subjects are analogous we can recognize most of the topics by reading the \nmost relevant words. \n* Topics 1, 4 and 8 are about politics.\n*  Topics 2, 3 and  6, are about race and religions.\n* Topics 5, 7 and 9 are sex questions\n*  Topic 10 is more contrasted and we couldn't recognize a clear subject, it seems to gather different hot social subjects (gender, guns, criminals)"
    },
    {
      "metadata": {
        "_uuid": "c8a0e77e646a61666d4944b9a44bad3eed3e453e"
      },
      "cell_type": "markdown",
      "source": "_**The clear separation in 4 group of subject let think we should try a lda with 4 topics. **_"
    },
    {
      "metadata": {
        "_uuid": "f3d8a3226fe59cc60ceedef658d5e99211a916da"
      },
      "cell_type": "markdown",
      "source": "## III-C. Recreate new Lda with 4 topics"
    },
    {
      "metadata": {
        "_uuid": "8f29efe4c51cd91e6d9b4b3d75b84c9b969bdef4"
      },
      "cell_type": "markdown",
      "source": "We already have preprocessed data, wo we will just recreate the Lda in itself. "
    },
    {
      "metadata": {
        "_uuid": "bf00f08d575be2f922ffc8895fa579b3fe9a6c52"
      },
      "cell_type": "markdown",
      "source": "### III-C.1. Creating lda model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d05c7084f54bf62087fe23c83b47ffb912c384c8"
      },
      "cell_type": "code",
      "source": "# Creating a lda model, which create 4 topics from the sincere questions\nimport warnings\nwarnings.filterwarnings('ignore')\nlda_model_sincere_4 = gensim.models.ldamodel.LdaModel(\n    corpus=sincere_corpus, num_topics=4, id2word=sincere_questions_dictionary,\n    random_state=25, passes=5)",
      "execution_count": 43,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "57301e4b852c66f6c2e15d2f577cf24e01ac8903"
      },
      "cell_type": "code",
      "source": "# Creating a lda model, which create 4 topics from the insincere questions\nlda_model_insincere_4 = gensim.models.ldamodel.LdaModel(\n    corpus=insincere_corpus, num_topics=4, id2word=insincere_questions_dictionary,\n    random_state=25, passes=5)",
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3be2c08c1531d5a4da5525c34ce774ce0688f2c0"
      },
      "cell_type": "code",
      "source": "# Printing the result of the modeling for sincere questions.\npprint(lda_model_sincere_4.print_topics())",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[(0,\n  '0.021*\"would\" + 0.008*\"us\" + 0.008*\"world\" + 0.008*\"people\" + 0.007*\"like\" '\n  '+ 0.007*\"think\" + 0.006*\"india\" + 0.006*\"old\" + 0.006*\"country\" + '\n  '0.005*\"many\"'),\n (1,\n  '0.014*\"like\" + 0.013*\"people\" + 0.010*\"someone\" + 0.010*\"life\" + '\n  '0.009*\"best\" + 0.009*\"would\" + 0.009*\"get\" + 0.009*\"know\" + 0.008*\"ever\" + '\n  '0.008*\"one\"'),\n (2,\n  '0.009*\"much\" + 0.008*\"time\" + 0.006*\"day\" + 0.005*\"used\" + 0.005*\"use\" + '\n  '0.004*\"system\" + 0.004*\"take\" + 0.004*\"long\" + 0.004*\"class\" + '\n  '0.004*\"water\"'),\n (3,\n  '0.020*\"best\" + 0.019*\"get\" + 0.009*\"good\" + 0.007*\"india\" + 0.006*\"job\" + '\n  '0.006*\"quora\" + 0.005*\"college\" + 0.005*\"engineering\" + 0.005*\"online\" + '\n  '0.005*\"university\"')]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6d82560ba0c2287ef923ad7e0560bf54ef96e1b7"
      },
      "cell_type": "code",
      "source": "# Printing the result of the modeling for insincere questions.\npprint(lda_model_insincere_4.print_topics())",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[(0,\n  '0.037*\"people\" + 0.015*\"white\" + 0.012*\"world\" + 0.011*\"americans\" + '\n  '0.010*\"chinese\" + 0.010*\"black\" + 0.009*\"country\" + 0.009*\"us\" + '\n  '0.008*\"muslims\" + 0.008*\"hate\"'),\n (1,\n  '0.032*\"women\" + 0.023*\"men\" + 0.015*\"girls\" + 0.014*\"sex\" + 0.013*\"like\" + '\n  '0.010*\"get\" + 0.008*\"would\" + 0.008*\"gay\" + 0.008*\"indian\" + 0.008*\"man\"'),\n (2,\n  '0.024*\"people\" + 0.020*\"quora\" + 0.011*\"muslims\" + 0.010*\"india\" + '\n  '0.008*\"questions\" + 0.008*\"god\" + 0.008*\"like\" + 0.008*\"many\" + '\n  '0.007*\"indians\" + 0.007*\"christians\"'),\n (3,\n  '0.031*\"trump\" + 0.010*\"liberals\" + 0.008*\"president\" + 0.008*\"would\" + '\n  '0.007*\"obama\" + 0.007*\"donald\" + 0.007*\"democrats\" + 0.006*\"us\" + '\n  '0.005*\"people\" + 0.005*\"right\"')]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "5ebfafc544d6554764fde787195ed3876b0134b9"
      },
      "cell_type": "markdown",
      "source": "### III-C.2. Visualization"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "32f0ac10d1d34310a91dd919cb64a1452fa16e8e"
      },
      "cell_type": "code",
      "source": "# Display the topic modeling for sincere questions.\npyLDAvis.gensim.prepare(lda_model_sincere_4, sincere_corpus, sincere_questions_dictionary)",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\ntopic                                                \n3      0.163952 -0.261155       1        1  27.851519\n1     -0.136546 -0.143456       2        1  27.332216\n0     -0.282503  0.148785       3        1  23.342737\n2      0.255096  0.255827       4        1  21.473526, topic_info=     Category          Freq   ...     loglift  logprob\nterm                          ...                     \n11    Default  56145.000000   ...     30.0000  30.0000\n462   Default  61552.000000   ...     29.0000  29.0000\n64    Default  57738.000000   ...     28.0000  28.0000\n345   Default  41514.000000   ...     27.0000  27.0000\n9     Default  40818.000000   ...     26.0000  26.0000\n269   Default  21168.000000   ...     25.0000  25.0000\n141   Default  21163.000000   ...     24.0000  24.0000\n104   Default  17832.000000   ...     23.0000  23.0000\n482   Default  14684.000000   ...     22.0000  22.0000\n61    Default  16279.000000   ...     21.0000  21.0000\n297   Default  14512.000000   ...     20.0000  20.0000\n1772  Default  15250.000000   ...     19.0000  19.0000\n1124  Default  13696.000000   ...     18.0000  18.0000\n15    Default  21825.000000   ...     17.0000  17.0000\n62    Default  13338.000000   ...     16.0000  16.0000\n339   Default  21083.000000   ...     15.0000  15.0000\n226   Default  12519.000000   ...     14.0000  14.0000\n125   Default  22360.000000   ...     13.0000  13.0000\n42    Default  12172.000000   ...     12.0000  12.0000\n644   Default   9713.000000   ...     11.0000  11.0000\n558   Default  10088.000000   ...     10.0000  10.0000\n1837  Default   9778.000000   ...      9.0000   9.0000\n277   Default  10797.000000   ...      8.0000   8.0000\n244   Default  10223.000000   ...      7.0000   7.0000\n72    Default  10053.000000   ...      6.0000   6.0000\n1258  Default   9862.000000   ...      5.0000   5.0000\n249   Default   9807.000000   ...      4.0000   4.0000\n99    Default   9582.000000   ...      3.0000   3.0000\n261   Default   9533.000000   ...      2.0000   2.0000\n85    Default   8418.000000   ...      1.0000   1.0000\n...       ...           ...   ...         ...      ...\n1349   Topic4   3954.963135   ...      1.5382  -6.0203\n2459   Topic4   4085.754883   ...      1.5382  -5.9878\n1728   Topic4   3768.897949   ...      1.5381  -6.0685\n662    Topic4   3659.785889   ...      1.5381  -6.0979\n1274   Topic4   3622.738281   ...      1.5381  -6.1080\n848    Topic4   3496.422119   ...      1.5381  -6.1435\n1764   Topic4   3525.195312   ...      1.5381  -6.1353\n3203   Topic4   3429.128174   ...      1.5381  -6.1630\n14     Topic4   3434.766602   ...      1.5381  -6.1613\n3415   Topic4   3297.162109   ...      1.5381  -6.2022\n4840   Topic4   3341.036865   ...      1.5381  -6.1890\n1790   Topic4   3260.350342   ...      1.5381  -6.2134\n940    Topic4   3154.689453   ...      1.5381  -6.2464\n3834   Topic4   3221.226318   ...      1.5381  -6.2255\n339    Topic4  14791.953125   ...      1.1840  -4.7012\n15     Topic4  12774.125000   ...      1.0027  -4.8479\n587    Topic4   7180.004395   ...      1.1237  -5.4240\n21     Topic4   8012.076660   ...      1.0489  -5.3143\n113    Topic4   7201.226562   ...      0.6841  -5.4210\n94     Topic4   7607.585938   ...      0.5701  -5.3661\n504    Topic4   6015.426270   ...      0.8360  -5.6009\n341    Topic4   6231.890137   ...      0.4635  -5.5656\n129    Topic4   6470.606934   ...      0.3626  -5.5280\n298    Topic4   4692.453125   ...      0.9738  -5.8493\n137    Topic4   5099.904785   ...      0.4292  -5.7661\n110    Topic4   5888.275391   ...     -0.3112  -5.6223\n282    Topic4   5703.202148   ...     -0.2124  -5.6542\n160    Topic4   4896.874512   ...     -0.1003  -5.8067\n51     Topic4   4479.308105   ...      0.6134  -5.8958\n1782   Topic4   4319.733887   ...      0.8909  -5.9321\n\n[208 rows x 6 columns], token_table=      Topic      Freq      Term\nterm                           \n449       1  0.999872   account\n12        3  0.999780    affect\n1276      3  0.999950       age\n1074      2  0.999783    always\n2906      3  0.999871   america\n256       3  0.999801  american\n717       1  0.999905       app\n378       2  0.999864       bad\n137       2  0.670098    become\n137       4  0.329842    become\n3203      4  0.999741  benefits\n462       1  0.685272      best\n462       2  0.314725      best\n228       1  0.563088    better\n228       2  0.292590    better\n228       3  0.143858    better\n228       4  0.000520    better\n183       3  0.999896     black\n1944      4  0.999946      body\n261       2  0.999968      book\n119       1  0.769499  business\n119       4  0.230429  business\n298       1  0.431276       buy\n298       4  0.568572       buy\n258       1  0.999865       car\n138       1  0.999897    career\n768       4  0.999923     cause\n1600      3  0.999725    causes\n401       3  0.999825     china\n1814      3  0.999794   chinese\n...     ...       ...       ...\n524       3  0.999808       usa\n94        1  0.456192       use\n94        2  0.164027       use\n94        4  0.379769       use\n21        1  0.239540      used\n21        2  0.147503      used\n21        4  0.612964      used\n4840      4  0.999757      visa\n918       1  0.237743      want\n918       2  0.762259      want\n168       3  0.999951       war\n1106      4  0.999894     water\n73        1  0.446147       way\n73        2  0.553843       way\n494       1  0.999791   website\n932       3  0.999800     white\n784       3  0.999889       win\n977       3  0.999863     women\n341       1  0.430490      work\n341       2  0.228090      work\n341       4  0.341368      work\n297       3  0.999976     world\n11        2  0.336696     would\n11        3  0.663294     would\n359       2  0.999942     write\n286       1  0.565109      year\n286       3  0.434887      year\n874       1  0.237038     years\n874       2  0.342156     years\n874       3  0.420782     years\n\n[217 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 2, 1, 3])",
            "text/html": "\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n\n\n<div id=\"ldavis_el231403996289335448724974352\"></div>\n<script type=\"text/javascript\">\n\nvar ldavis_el231403996289335448724974352_data = {\"mdsDat\": {\"x\": [0.16395185599980613, -0.13654579293852137, -0.2825025415254892, 0.25509647846420436], \"y\": [-0.2611553908203012, -0.14345628290560034, 0.14878459783377834, 0.2558270758921231], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [27.851518630981445, 27.332216262817383, 23.342737197875977, 21.473526000976562]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"Freq\": [56145.0, 61552.0, 57738.0, 41514.0, 40818.0, 21168.0, 21163.0, 17832.0, 14684.0, 16279.0, 14512.0, 15250.0, 13696.0, 21825.0, 13338.0, 21083.0, 12519.0, 22360.0, 12172.0, 9713.0, 10088.0, 9778.0, 10797.0, 10223.0, 10053.0, 9862.0, 9807.0, 9582.0, 9533.0, 8418.0, 13695.3525390625, 12171.57421875, 10796.8642578125, 10222.5654296875, 9806.873046875, 9861.6484375, 8816.173828125, 8340.798828125, 8143.53125, 7505.94384765625, 7062.7607421875, 6735.62109375, 6499.666015625, 6577.90673828125, 6394.22412109375, 6300.04833984375, 5960.00146484375, 5756.8896484375, 5772.6630859375, 5691.67236328125, 5747.216796875, 5536.76416015625, 5386.33935546875, 5471.91748046875, 5554.9638671875, 5372.3623046875, 5337.15966796875, 5365.6767578125, 5116.61328125, 4992.94873046875, 42179.8203125, 39429.5859375, 19510.21875, 8412.2197265625, 14471.03515625, 8382.5869140625, 8666.1005859375, 7274.93408203125, 8101.69140625, 9139.1357421875, 8682.7314453125, 6901.20556640625, 7859.4833984375, 8617.939453125, 7010.857421875, 21163.07421875, 21167.6640625, 17831.23828125, 16278.845703125, 15250.0146484375, 13337.3349609375, 12519.107421875, 10053.1513671875, 9581.974609375, 9532.5224609375, 8326.365234375, 8324.2060546875, 7917.34765625, 7725.1376953125, 7443.46728515625, 7385.08984375, 7311.59619140625, 6939.8369140625, 6759.60888671875, 6681.22998046875, 6431.251953125, 6177.974609375, 5823.56640625, 5904.07080078125, 5867.92431640625, 5888.5634765625, 5672.166015625, 5484.42138671875, 5233.32666015625, 5206.2138671875, 28750.314453125, 27139.07421875, 12141.7509765625, 8195.3662109375, 10361.494140625, 13455.7607421875, 15546.611328125, 18904.49609375, 19371.8359375, 18308.72265625, 10778.9326171875, 12033.22265625, 9872.3212890625, 9050.6884765625, 7838.400390625, 7737.88427734375, 14683.263671875, 14511.5771484375, 10087.4501953125, 9777.6591796875, 8417.376953125, 8366.802734375, 7945.5595703125, 6882.55615234375, 6470.5703125, 6547.14111328125, 6257.3388671875, 5911.41064453125, 5767.6552734375, 5684.716796875, 5438.5048828125, 5185.78515625, 5000.19384765625, 4832.17138671875, 4467.818359375, 4429.7421875, 4493.2109375, 4201.6796875, 4183.07958984375, 4094.864990234375, 4140.5498046875, 4035.35107421875, 3844.033203125, 3941.435791015625, 3794.3095703125, 3785.71630859375, 37240.52734375, 12487.455078125, 7435.76806640625, 13678.8662109375, 11260.837890625, 9415.6162109375, 12763.9755859375, 6707.259765625, 6234.84228515625, 5448.154296875, 9712.2763671875, 7292.11328125, 6933.97802734375, 7023.96337890625, 5785.8251953125, 5575.00244140625, 5509.1533203125, 5214.87060546875, 5173.24853515625, 4992.505859375, 4944.97607421875, 4680.5908203125, 4642.19091796875, 4379.7880859375, 4231.0048828125, 4255.39697265625, 4154.00732421875, 3954.963134765625, 4085.7548828125, 3768.89794921875, 3659.785888671875, 3622.73828125, 3496.422119140625, 3525.1953125, 3429.128173828125, 3434.7666015625, 3297.162109375, 3341.036865234375, 3260.350341796875, 3154.689453125, 3221.226318359375, 14791.953125, 12774.125, 7180.00439453125, 8012.07666015625, 7201.2265625, 7607.5859375, 6015.42626953125, 6231.89013671875, 6470.60693359375, 4692.453125, 5099.90478515625, 5888.275390625, 5703.2021484375, 4896.87451171875, 4479.30810546875, 4319.73388671875], \"Term\": [\"would\", \"best\", \"get\", \"like\", \"people\", \"someone\", \"life\", \"know\", \"us\", \"ever\", \"world\", \"person\", \"job\", \"time\", \"feel\", \"much\", \"mean\", \"think\", \"quora\", \"day\", \"old\", \"country\", \"college\", \"engineering\", \"things\", \"online\", \"university\", \"love\", \"book\", \"trump\", \"job\", \"quora\", \"college\", \"engineering\", \"university\", \"online\", \"company\", \"student\", \"study\", \"science\", \"number\", \"social\", \"computer\", \"career\", \"students\", \"questions\", \"account\", \"software\", \"learning\", \"exam\", \"data\", \"app\", \"course\", \"companies\", \"car\", \"website\", \"google\", \"top\", \"jee\", \"major\", \"best\", \"get\", \"good\", \"business\", \"india\", \"start\", \"better\", \"school\", \"year\", \"use\", \"way\", \"learn\", \"work\", \"one\", \"find\", \"life\", \"someone\", \"know\", \"ever\", \"person\", \"feel\", \"mean\", \"things\", \"love\", \"book\", \"bad\", \"even\", \"stop\", \"english\", \"something\", \"thing\", \"girl\", \"language\", \"friend\", \"sex\", \"real\", \"tell\", \"friends\", \"phone\", \"never\", \"write\", \"relationship\", \"always\", \"guy\", \"read\", \"like\", \"people\", \"want\", \"really\", \"become\", \"make\", \"one\", \"would\", \"best\", \"get\", \"way\", \"good\", \"think\", \"time\", \"new\", \"find\", \"us\", \"world\", \"old\", \"country\", \"trump\", \"happen\", \"live\", \"countries\", \"war\", \"women\", \"china\", \"american\", \"man\", \"parents\", \"age\", \"men\", \"usa\", \"makes\", \"america\", \"win\", \"affect\", \"black\", \"white\", \"god\", \"eat\", \"causes\", \"chinese\", \"date\", \"face\", \"light\", \"would\", \"think\", \"indian\", \"people\", \"india\", \"many\", \"like\", \"could\", \"year\", \"years\", \"day\", \"system\", \"water\", \"class\", \"movie\", \"days\", \"cost\", \"happens\", \"examples\", \"body\", \"food\", \"cause\", \"less\", \"considered\", \"energy\", \"part\", \"technology\", \"tips\", \"marketing\", \"taking\", \"increase\", \"term\", \"health\", \"single\", \"benefits\", \"space\", \"per\", \"visa\", \"short\", \"types\", \"studying\", \"much\", \"time\", \"long\", \"used\", \"take\", \"use\", \"difference\", \"work\", \"many\", \"buy\", \"become\", \"good\", \"one\", \"make\", \"different\", \"made\"], \"Total\": [56145.0, 61552.0, 57738.0, 41514.0, 40818.0, 21168.0, 21163.0, 17832.0, 14684.0, 16279.0, 14512.0, 15250.0, 13696.0, 21825.0, 13338.0, 21083.0, 12519.0, 22360.0, 12172.0, 9713.0, 10088.0, 9778.0, 10797.0, 10223.0, 10053.0, 9862.0, 9807.0, 9582.0, 9533.0, 8418.0, 13696.1142578125, 12172.34375, 10797.6220703125, 10223.314453125, 9807.6279296875, 9862.4140625, 8816.939453125, 8341.560546875, 8144.29052734375, 7506.70166015625, 7063.5439453125, 6736.40234375, 6500.42138671875, 6578.67578125, 6394.9794921875, 6300.810546875, 5960.76318359375, 5757.6474609375, 5773.4248046875, 5692.42529296875, 5747.9775390625, 5537.52587890625, 5387.0947265625, 5472.68798828125, 5555.7490234375, 5373.12255859375, 5337.919921875, 5366.455078125, 5117.36083984375, 4993.7216796875, 61552.17578125, 57738.83203125, 37431.98046875, 10931.794921875, 28696.90234375, 12172.8583984375, 15390.1318359375, 10480.6669921875, 14337.056640625, 20033.2265625, 19462.19140625, 10826.2783203125, 18255.943359375, 32844.63671875, 16285.060546875, 21163.841796875, 21168.435546875, 17832.009765625, 16279.61328125, 15250.7880859375, 13338.09765625, 12519.875, 10053.9169921875, 9582.73046875, 9533.3037109375, 8327.1318359375, 8324.98046875, 7918.119140625, 7725.91015625, 7444.2294921875, 7385.84912109375, 7312.35498046875, 6940.60986328125, 6760.36572265625, 6681.9921875, 6432.02685546875, 6178.74462890625, 5824.32470703125, 5904.84375, 5868.69384765625, 5889.34130859375, 5672.927734375, 5485.19091796875, 5234.08251953125, 5206.97998046875, 41514.80859375, 40818.453125, 15928.9599609375, 9799.693359375, 15461.92578125, 25209.10546875, 32844.63671875, 56145.546875, 61552.17578125, 57738.83203125, 19462.19140625, 37431.98046875, 22360.2890625, 21825.333984375, 12776.966796875, 16285.060546875, 14684.03515625, 14512.341796875, 10088.2177734375, 9778.421875, 8418.130859375, 8367.568359375, 7946.330078125, 6883.31494140625, 6471.3203125, 6547.8994140625, 6258.0966796875, 5912.17529296875, 5768.42138671875, 5685.4921875, 5439.27392578125, 5186.54248046875, 5000.96044921875, 4832.94873046875, 4468.576171875, 4430.49365234375, 4493.98876953125, 4202.4365234375, 4183.837890625, 4095.625732421875, 4141.32080078125, 4036.111083984375, 3844.790283203125, 3942.212646484375, 3795.072998046875, 3786.48095703125, 56145.546875, 22360.2890625, 10634.7216796875, 40818.453125, 28696.90234375, 20968.23828125, 41514.80859375, 15749.34375, 14337.056640625, 12947.3134765625, 9713.0400390625, 7292.8798828125, 6934.73193359375, 7024.74609375, 5786.59619140625, 5575.77294921875, 5509.91552734375, 5215.63671875, 5174.0107421875, 4993.2685546875, 4945.7392578125, 4681.3603515625, 4642.970703125, 4380.55859375, 4231.75732421875, 4256.17041015625, 4154.78271484375, 3955.72900390625, 4086.552490234375, 3769.6787109375, 3660.550048828125, 3623.49853515625, 3497.18505859375, 3525.976806640625, 3429.889404296875, 3435.52978515625, 3297.921630859375, 3341.811767578125, 3261.116455078125, 3155.445556640625, 3222.027099609375, 21083.328125, 21825.333984375, 10868.984375, 13070.90625, 16920.89453125, 20033.2265625, 12142.47265625, 18255.943359375, 20968.23828125, 8252.251953125, 15461.92578125, 37431.98046875, 32844.63671875, 25209.10546875, 11295.1904296875, 8253.708984375], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2782000303268433, 1.2781000137329102, 1.2781000137329102, 1.2781000137329102, 1.2781000137329102, 1.2781000137329102, 1.2781000137329102, 1.2781000137329102, 1.2781000137329102, 1.2781000137329102, 0.9003000259399414, 0.8968999981880188, 0.6266999840736389, 1.0162999629974365, 0.5935999751091003, 0.9052000045776367, 0.7039999961853027, 0.9132000207901001, 0.7074999809265137, 0.4934999942779541, 0.47110000252723694, 0.828000009059906, 0.43549999594688416, -0.059700001031160355, 0.43549999594688416, 1.2970999479293823, 1.2970999479293823, 1.2970999479293823, 1.2970999479293823, 1.2970999479293823, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 1.2970000505447388, 0.9297000169754028, 0.8888999819755554, 1.0255999565124512, 1.118299961090088, 0.8967999815940857, 0.6693000197410583, 0.5491999983787537, 0.2085999995470047, 0.14100000262260437, 0.1485999971628189, 0.7062000036239624, 0.1623000055551529, 0.4796000123023987, 0.41690000891685486, 0.8084999918937683, 0.5529999732971191, 1.454800009727478, 1.454800009727478, 1.454800009727478, 1.454800009727478, 1.454800009727478, 1.454800009727478, 1.454800009727478, 1.454800009727478, 1.454800009727478, 1.454800009727478, 1.454800009727478, 1.454800009727478, 1.454800009727478, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.454699993133545, 1.0442999601364136, 0.8723000288009644, 1.097100019454956, 0.36160001158714294, 0.5194000005722046, 0.65420001745224, 0.27549999952316284, 0.6013000011444092, 0.6222000122070312, 0.5892999768257141, 1.5383000373840332, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.5382000207901, 1.538100004196167, 1.538100004196167, 1.538100004196167, 1.538100004196167, 1.538100004196167, 1.538100004196167, 1.538100004196167, 1.538100004196167, 1.538100004196167, 1.538100004196167, 1.538100004196167, 1.538100004196167, 1.184000015258789, 1.0026999711990356, 1.1237000226974487, 1.0489000082015991, 0.6840999722480774, 0.5701000094413757, 0.8360000252723694, 0.4634999930858612, 0.3625999987125397, 0.973800003528595, 0.4291999936103821, -0.31119999289512634, -0.21240000426769257, -0.10029999911785126, 0.6133999824523926, 0.8909000158309937], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.038300037384033, -5.156199932098389, -5.276100158691406, -5.330699920654297, -5.372300148010254, -5.366700172424316, -5.478799819946289, -5.534200191497803, -5.55810022354126, -5.639599800109863, -5.700500011444092, -5.747900009155273, -5.783599853515625, -5.771599769592285, -5.799900054931641, -5.814799785614014, -5.870299816131592, -5.904900074005127, -5.902200222015381, -5.916299819946289, -5.906599998474121, -5.943900108337402, -5.971499919891357, -5.955699920654297, -5.940700054168701, -5.974100112915039, -5.980599880218506, -5.975299835205078, -6.022900104522705, -6.047299861907959, -3.9133999347686768, -3.980799913406372, -4.6844000816345215, -5.525700092315674, -4.9832000732421875, -5.529200077056885, -5.4959001541137695, -5.670899868011475, -5.563300132751465, -5.442800045013428, -5.49399995803833, -5.723599910736084, -5.593599796295166, -5.501500129699707, -5.707900047302246, -4.5843000411987305, -4.584000110626221, -4.7555999755859375, -4.846700191497803, -4.911900043487549, -5.046000003814697, -5.109300136566162, -5.32859992980957, -5.3765997886657715, -5.381800174713135, -5.517099857330322, -5.517399787902832, -5.567500114440918, -5.5920000076293945, -5.629199981689453, -5.6371002197265625, -5.64709997177124, -5.69920015335083, -5.725599765777588, -5.737199783325195, -5.775400161743164, -5.815499782562256, -5.874599933624268, -5.860899925231934, -5.867000102996826, -5.863500118255615, -5.901000022888184, -5.934599876403809, -5.981500148773193, -5.986700057983398, -4.277900218963623, -4.3354997634887695, -5.139900207519531, -5.5329999923706055, -5.298399925231934, -5.037099838256836, -4.8927001953125, -4.6971001625061035, -4.672699928283691, -4.729100227355957, -5.258900165557861, -5.148900032043457, -5.346799850463867, -5.433700084686279, -5.577499866485596, -5.590400218963623, -4.791999816894531, -4.803800106048584, -5.167399883270264, -5.198599815368652, -5.348400115966797, -5.354499816894531, -5.406099796295166, -5.549799919128418, -5.611499786376953, -5.599699974060059, -5.644999980926514, -5.701900005340576, -5.726500034332275, -5.741000175476074, -5.785200119018555, -5.832799911499023, -5.86929988861084, -5.90339994430542, -5.981800079345703, -5.9903998374938965, -5.976200103759766, -6.043300151824951, -6.047699928283691, -6.068999767303467, -6.0578999519348145, -6.083600044250488, -6.132199764251709, -6.1072001457214355, -6.145199775695801, -6.147500038146973, -3.861299991607666, -4.953999996185303, -5.472400188446045, -4.8628997802734375, -5.057400226593018, -5.236400127410889, -4.93209981918335, -5.5756001472473145, -5.648600101470947, -5.7835001945495605, -5.1219000816345215, -5.4085001945495605, -5.458799839019775, -5.445899963378906, -5.639900207519531, -5.677000045776367, -5.688899993896484, -5.743800163269043, -5.751800060272217, -5.787300109863281, -5.796899795532227, -5.851900100708008, -5.860099792480469, -5.918300151824951, -5.9527997970581055, -5.9471001625061035, -5.971199989318848, -6.020299911499023, -5.987800121307373, -6.06850004196167, -6.097899913787842, -6.107999801635742, -6.143499851226807, -6.135300159454346, -6.163000106811523, -6.161300182342529, -6.202199935913086, -6.189000129699707, -6.213399887084961, -6.246399879455566, -6.225500106811523, -4.701200008392334, -4.847899913787842, -5.423999786376953, -5.314300060272217, -5.421000003814697, -5.366099834442139, -5.600900173187256, -5.5655999183654785, -5.5279998779296875, -5.849299907684326, -5.76609992980957, -5.622300148010254, -5.654200077056885, -5.806700229644775, -5.8958001136779785, -5.93209981918335]}, \"token.table\": {\"Topic\": [1, 3, 3, 2, 3, 3, 1, 2, 2, 4, 4, 1, 2, 1, 2, 3, 4, 3, 4, 2, 1, 4, 1, 4, 1, 1, 4, 3, 3, 3, 4, 1, 1, 1, 1, 4, 4, 2, 3, 4, 3, 3, 1, 1, 3, 4, 4, 1, 3, 4, 1, 2, 3, 4, 3, 4, 1, 2, 2, 2, 1, 4, 3, 2, 1, 2, 4, 4, 2, 2, 1, 2, 2, 3, 1, 2, 4, 1, 2, 3, 4, 4, 4, 1, 3, 4, 1, 3, 1, 1, 2, 2, 1, 2, 1, 4, 2, 3, 2, 3, 3, 2, 3, 4, 2, 2, 4, 1, 1, 2, 3, 4, 3, 3, 1, 3, 4, 4, 2, 3, 4, 1, 3, 4, 2, 1, 2, 1, 3, 1, 2, 3, 4, 1, 3, 4, 2, 3, 4, 2, 2, 1, 1, 2, 2, 2, 3, 2, 1, 2, 1, 2, 4, 4, 1, 1, 2, 2, 4, 1, 2, 2, 1, 1, 1, 4, 4, 1, 2, 3, 4, 4, 4, 2, 4, 2, 2, 2, 3, 2, 4, 4, 1, 3, 4, 1, 3, 3, 1, 2, 4, 1, 2, 4, 4, 1, 2, 3, 4, 1, 2, 1, 3, 3, 3, 1, 2, 4, 3, 2, 3, 2, 1, 3, 1, 2, 3], \"Freq\": [0.9998719692230225, 0.999779999256134, 0.9999496340751648, 0.9997828602790833, 0.9998710751533508, 0.9998012185096741, 0.9999050498008728, 0.9998641014099121, 0.6700976490974426, 0.3298424780368805, 0.999740719795227, 0.6852722764015198, 0.314724862575531, 0.5630881190299988, 0.29259008169174194, 0.1438584178686142, 0.0005198136204853654, 0.9998961091041565, 0.9999462366104126, 0.9999681711196899, 0.7694985270500183, 0.2304287701845169, 0.43127620220184326, 0.5685720443725586, 0.9998651742935181, 0.999897301197052, 0.999923050403595, 0.9997246861457825, 0.9998247623443604, 0.9997944831848145, 0.9998937845230103, 0.9999423623085022, 0.9998742938041687, 0.9998934268951416, 0.9999351501464844, 0.9998725056648254, 0.9998338222503662, 0.4146839380264282, 0.4258590042591095, 0.1594352126121521, 0.9999542236328125, 0.9999568462371826, 0.9997968077659607, 0.9998299479484558, 0.9996923804283142, 0.9998929500579834, 0.9998613595962524, 0.3150099813938141, 0.1895824670791626, 0.495368629693985, 0.21239128708839417, 0.08879885822534561, 0.30225253105163574, 0.39654046297073364, 0.999922513961792, 0.9998210668563843, 0.9999692440032959, 0.9998822212219238, 0.9998822212219238, 0.999962329864502, 0.9999253153800964, 0.999804675579071, 0.9997172951698303, 0.9999176859855652, 0.4305172860622406, 0.4751594364643097, 0.09431957453489304, 0.9998505115509033, 0.999945878982544, 0.999944269657135, 0.6829026341438293, 0.31710028648376465, 0.9999514818191528, 0.9998472332954407, 0.5212120413780212, 0.32146307826042175, 0.15729865431785583, 0.9998276829719543, 0.9997931718826294, 0.999932050704956, 0.9998779296875, 0.9996611475944519, 0.9998497366905212, 0.5042704343795776, 0.3924116790294647, 0.10332125425338745, 0.30071309208869934, 0.6992190480232239, 0.9999294877052307, 0.9999186396598816, 0.9999433755874634, 0.9999121427536011, 0.6374304890632629, 0.3625437915325165, 0.9999264478683472, 0.9997909069061279, 0.9999602437019348, 0.9998729825019836, 0.6925239562988281, 0.3074565529823303, 0.9999584555625916, 0.07599606364965439, 0.2634100615978241, 0.6605952978134155, 0.9999237656593323, 0.4765130579471588, 0.5234010815620422, 0.9998554587364197, 0.14970780909061432, 0.5337753891944885, 0.12225741147994995, 0.19425520300865173, 0.9998037219047546, 0.9999269247055054, 0.24236656725406647, 0.4490601420402527, 0.30860960483551025, 0.9998648166656494, 0.9999300837516785, 0.9998953938484192, 0.9998969435691833, 0.2603479027748108, 0.03803953528404236, 0.7015970349311829, 0.9998817443847656, 0.38647669553756714, 0.6134476065635681, 0.9999229907989502, 0.9998793005943298, 0.26238682866096497, 0.4733497202396393, 0.09063884615898132, 0.17363566160202026, 0.9999580383300781, 0.9999134540557861, 0.9997249841690063, 0.6648708581924438, 0.33511802554130554, 0.9997205138206482, 0.9999483227729797, 0.9998571276664734, 0.9998713731765747, 0.9999717473983765, 0.9998117685317993, 0.9998403787612915, 0.8362506628036499, 0.1636785864830017, 0.9998364448547363, 0.6941351890563965, 0.3058011531829834, 0.9999065399169922, 0.9998515248298645, 0.9996576309204102, 0.999722957611084, 0.9999402761459351, 0.9998875260353088, 0.9999794363975525, 0.9998348355293274, 0.9998458027839661, 0.6886632442474365, 0.31134840846061707, 0.9998586773872375, 0.9999328255653381, 0.9998468160629272, 0.9999643564224243, 0.9996812343597412, 0.9998793601989746, 0.289996474981308, 0.028189998120069504, 0.2562512159347534, 0.42556852102279663, 0.9998199343681335, 0.999811589717865, 0.9998794794082642, 0.9998624324798584, 0.9998850226402283, 0.9999088048934937, 0.44149696826934814, 0.558445394039154, 0.41470155119895935, 0.5852831602096558, 0.9998157024383545, 0.9999151825904846, 0.9998656511306763, 0.9998587965965271, 0.9999359846115112, 0.9999294877052307, 0.9998079538345337, 0.45619210600852966, 0.16402749717235565, 0.37976908683776855, 0.23953962326049805, 0.14750316739082336, 0.612964391708374, 0.9997571110725403, 0.237743079662323, 0.7622594237327576, 0.9999505281448364, 0.9998944401741028, 0.446147084236145, 0.553843080997467, 0.9997910857200623, 0.9997997283935547, 0.9998885989189148, 0.9998626112937927, 0.4304899275302887, 0.2280901074409485, 0.34136828780174255, 0.9999764561653137, 0.3366963267326355, 0.6632938981056213, 0.9999420642852783, 0.5651090145111084, 0.43488702178001404, 0.23703758418560028, 0.34215593338012695, 0.42078226804733276], \"Term\": [\"account\", \"affect\", \"age\", \"always\", \"america\", \"american\", \"app\", \"bad\", \"become\", \"become\", \"benefits\", \"best\", \"best\", \"better\", \"better\", \"better\", \"better\", \"black\", \"body\", \"book\", \"business\", \"business\", \"buy\", \"buy\", \"car\", \"career\", \"cause\", \"causes\", \"china\", \"chinese\", \"class\", \"college\", \"companies\", \"company\", \"computer\", \"considered\", \"cost\", \"could\", \"could\", \"could\", \"countries\", \"country\", \"course\", \"data\", \"date\", \"day\", \"days\", \"difference\", \"difference\", \"difference\", \"different\", \"different\", \"different\", \"different\", \"eat\", \"energy\", \"engineering\", \"english\", \"even\", \"ever\", \"exam\", \"examples\", \"face\", \"feel\", \"find\", \"find\", \"find\", \"food\", \"friend\", \"friends\", \"get\", \"get\", \"girl\", \"god\", \"good\", \"good\", \"good\", \"google\", \"guy\", \"happen\", \"happens\", \"health\", \"increase\", \"india\", \"india\", \"india\", \"indian\", \"indian\", \"jee\", \"job\", \"know\", \"language\", \"learn\", \"learn\", \"learning\", \"less\", \"life\", \"light\", \"like\", \"like\", \"live\", \"long\", \"long\", \"long\", \"love\", \"made\", \"made\", \"major\", \"make\", \"make\", \"make\", \"make\", \"makes\", \"man\", \"many\", \"many\", \"many\", \"marketing\", \"mean\", \"men\", \"movie\", \"much\", \"much\", \"much\", \"never\", \"new\", \"new\", \"number\", \"old\", \"one\", \"one\", \"one\", \"one\", \"online\", \"parents\", \"part\", \"people\", \"people\", \"per\", \"person\", \"phone\", \"questions\", \"quora\", \"read\", \"real\", \"really\", \"really\", \"relationship\", \"school\", \"school\", \"science\", \"sex\", \"short\", \"single\", \"social\", \"software\", \"someone\", \"something\", \"space\", \"start\", \"start\", \"stop\", \"student\", \"students\", \"study\", \"studying\", \"system\", \"take\", \"take\", \"take\", \"take\", \"taking\", \"technology\", \"tell\", \"term\", \"thing\", \"things\", \"think\", \"think\", \"time\", \"time\", \"tips\", \"top\", \"trump\", \"types\", \"university\", \"us\", \"usa\", \"use\", \"use\", \"use\", \"used\", \"used\", \"used\", \"visa\", \"want\", \"want\", \"war\", \"water\", \"way\", \"way\", \"website\", \"white\", \"win\", \"women\", \"work\", \"work\", \"work\", \"world\", \"would\", \"would\", \"write\", \"year\", \"year\", \"years\", \"years\", \"years\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 2, 1, 3]};\n\nfunction LDAvis_load_lib(url, callback){\n  var s = document.createElement('script');\n  s.src = url;\n  s.async = true;\n  s.onreadystatechange = s.onload = callback;\n  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n  document.getElementsByTagName(\"head\")[0].appendChild(s);\n}\n\nif(typeof(LDAvis) !== \"undefined\"){\n   // already loaded: just create the visualization\n   !function(LDAvis){\n       new LDAvis(\"#\" + \"ldavis_el231403996289335448724974352\", ldavis_el231403996289335448724974352_data);\n   }(LDAvis);\n}else if(typeof define === \"function\" && define.amd){\n   // require.js is available: use it to load d3/LDAvis\n   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n   require([\"d3\"], function(d3){\n      window.d3 = d3;\n      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n        new LDAvis(\"#\" + \"ldavis_el231403996289335448724974352\", ldavis_el231403996289335448724974352_data);\n      });\n    });\n}else{\n    // require.js not available: dynamically load d3 & LDAvis\n    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n                 new LDAvis(\"#\" + \"ldavis_el231403996289335448724974352\", ldavis_el231403996289335448724974352_data);\n            })\n         });\n}\n</script>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "b01440979eda6791a9231b680d5e7e0e3794cbe4"
      },
      "cell_type": "markdown",
      "source": "The 4 topics created by the lda model are very distinct, this is better than the test with 10 topics. \nWe still can't differenciate clearly the subjects of the topics. Some words come back a lot \"best\", \"guess\", \"world\", \"people\".\nThis tend to show that the sincere question have various subject and there is no common theme around them. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c16978717b1b80202d63153096fc65a3bb501747"
      },
      "cell_type": "code",
      "source": "# # Display the topic modeling for insincere questions.\npyLDAvis.gensim.prepare(lda_model_insincere_4, insincere_corpus, insincere_questions_dictionary)",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\ntopic                                                \n3      0.029690  0.239387       1        1  27.428501\n0      0.163631  0.026489       2        1  26.352978\n1     -0.296509 -0.040013       3        1  23.656755\n2      0.103187 -0.225863       4        1  22.561762, topic_info=     Category          Freq       Term         Total  loglift  logprob\nterm                                                                  \n278   Default   5536.000000      women   5536.000000  30.0000  30.0000\n122   Default   6078.000000      trump   6078.000000  29.0000  29.0000\n136   Default  12113.000000     people  12113.000000  28.0000  28.0000\n393   Default   3926.000000        men   3926.000000  27.0000  27.0000\n191   Default   3237.000000      quora   3237.000000  26.0000  26.0000\n249   Default   2505.000000      girls   2505.000000  25.0000  25.0000\n194   Default   2360.000000        sex   2360.000000  24.0000  24.0000\n5     Default   2338.000000      world   2338.000000  23.0000  23.0000\n515   Default   3581.000000      white   3581.000000  22.0000  22.0000\n171   Default   2051.000000   liberals   2051.000000  21.0000  21.0000\n237   Default   1968.000000    chinese   1968.000000  20.0000  20.0000\n197   Default   3345.000000    muslims   3345.000000  19.0000  19.0000\n367   Default   1733.000000    country   1733.000000  18.0000  18.0000\n176   Default   3039.000000      india   3039.000000  17.0000  17.0000\n91    Default   2714.000000  americans   2714.000000  16.0000  16.0000\n418   Default   1389.000000  questions   1389.000000  15.0000  15.0000\n130   Default   1594.000000  president   1594.000000  14.0000  14.0000\n510   Default   2642.000000      black   2642.000000  13.0000  13.0000\n83    Default   1325.000000        god   1325.000000  12.0000  12.0000\n25    Default   1364.000000        gay   1364.000000  11.0000  11.0000\n1018  Default   1311.000000        man   1311.000000  10.0000  10.0000\n263   Default   2853.000000         us   2853.000000   9.0000   9.0000\n570   Default   1415.000000      obama   1415.000000   8.0000   8.0000\n668   Default   1403.000000     donald   1403.000000   7.0000   7.0000\n47    Default   1345.000000      china   1345.000000   6.0000   6.0000\n45    Default   1238.000000      woman   1238.000000   5.0000   5.0000\n139   Default   1338.000000  countries   1338.000000   4.0000   4.0000\n231   Default   2444.000000    indians   2444.000000   3.0000   3.0000\n680   Default   1351.000000  democrats   1351.000000   2.0000   2.0000\n1848  Default   1269.000000     racist   1269.000000   1.0000   1.0000\n...       ...           ...        ...           ...      ...      ...\n3775   Topic4    356.560089      tamil    357.287598   1.4869  -6.1281\n97     Topic4    328.299042   language    329.027985   1.4867  -6.2107\n434    Topic4    324.709229    english    325.437225   1.4867  -6.2217\n398    Topic4    317.481323    atheist    318.207520   1.4866  -6.2442\n2675   Topic4    318.730835      bible    319.459900   1.4866  -6.2402\n716    Topic4    320.231506       dumb    320.972748   1.4866  -6.2356\n101    Topic4    314.564545      speak    315.298187   1.4866  -6.2534\n1312   Topic4    312.723450       hell    313.458313   1.4866  -6.2593\n436    Topic4    298.746735      hindi    299.465820   1.4865  -6.3050\n54     Topic4    302.737579   superior    303.484070   1.4865  -6.2917\n4050   Topic4    318.306610       body    319.091949   1.4864  -6.2416\n4305   Topic4    346.158905      might    347.024963   1.4864  -6.1577\n246    Topic4    796.351685   religion    799.294617   1.4852  -5.3246\n197    Topic4   1830.795898    muslims   3345.316895   0.8861  -4.4921\n176    Topic4   1611.784424      india   3039.543457   0.8545  -4.6195\n136    Topic4   3970.960205     people  12113.837891   0.3736  -3.7178\n652    Topic4    709.376465      islam   1074.548096   1.0736  -5.4402\n231    Topic4   1132.744263    indians   2444.744629   0.7196  -4.9722\n350    Topic4    771.605225    believe   1443.618896   0.8625  -5.3561\n162    Topic4   1231.438110       many   3387.362793   0.4770  -4.8887\n230    Topic4    989.949402     indian   2988.458984   0.3841  -5.1069\n346    Topic4   1246.700684       like   5650.721680  -0.0224  -4.8763\n190    Topic4    741.733398     muslim   1951.277100   0.5217  -5.3956\n27     Topic4    665.729187       know   1578.930664   0.6253  -5.5037\n323    Topic4    900.344482      think   3693.443848   0.0774  -5.2018\n96     Topic4    648.305847       even   1639.428711   0.5612  -5.5302\n181    Topic4    524.620056       kill    945.330627   0.9001  -5.7419\n135    Topic4    656.762451       hate   2247.354492   0.2587  -5.5173\n90     Topic4    642.303040      would   4052.386230  -0.3531  -5.5395\n256    Topic4    568.520081        one   1839.306152   0.3148  -5.6616\n\n[230 rows x 6 columns], token_table=      Topic      Freq       Term\nterm                            \n838       2  0.999502    african\n296       1  0.382134    america\n296       2  0.617381    america\n39        1  0.328812   american\n39        2  0.547832   american\n39        3  0.123304   american\n91        1  0.243832  americans\n91        2  0.755805  americans\n252       4  0.997832     answer\n184       4  0.997775    answers\n655       1  0.619862       anti\n655       4  0.379881       anti\n79        2  0.997613      arabs\n1094      2  0.999100     asians\n1738      4  0.997100     asking\n398       4  0.996205    atheist\n467       4  0.999639   atheists\n350       1  0.310331    believe\n350       2  0.155166    believe\n350       4  0.534767    believe\n2675      4  0.998560      bible\n941       2  0.104586        big\n941       3  0.894288        big\n3021      4  0.997688        bjp\n510       2  0.713796      black\n510       3  0.285745      black\n12        2  0.997703     blacks\n424       1  0.998431      blame\n4050      4  0.996578       body\n934       3  0.999313       boys\n...     ...       ...        ...\n323       1  0.244217      think\n323       2  0.332752      think\n323       3  0.179237      think\n323       4  0.243675      think\n121       2  0.998633    towards\n122       1  0.999940      trump\n263       1  0.417312         us\n263       2  0.582695         us\n713       1  0.224135        usa\n713       2  0.775386        usa\n20        1  0.998650       vote\n31        1  0.174544       want\n31        2  0.253089       want\n31        3  0.485669       want\n31        4  0.086836       want\n1361      2  0.999085       west\n2091      2  0.995367    western\n2091      3  0.004248    western\n515       2  0.811656      white\n515       3  0.188186      white\n1098      2  0.997396     whites\n45        3  0.999555      woman\n278       3  0.999919      women\n5         2  0.999640      world\n90        1  0.388907      would\n90        2  0.114747      would\n90        3  0.337826      would\n90        4  0.158425      would\n1380      2  0.044998       year\n1380      3  0.955262       year\n\n[267 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 2, 3])",
            "text/html": "\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n\n\n<div id=\"ldavis_el231403994409235285614350760\"></div>\n<script type=\"text/javascript\">\n\nvar ldavis_el231403994409235285614350760_data = {\"mdsDat\": {\"x\": [0.029690436242148056, 0.16363091656523818, -0.2965086821053107, 0.1031873292979245], \"y\": [0.2393869316657852, 0.02648904145037692, -0.040013166433433826, -0.2258628066827285], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [27.42850112915039, 26.352977752685547, 23.656755447387695, 22.5617618560791]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"Freq\": [5536.0, 6078.0, 12113.0, 3926.0, 3237.0, 2505.0, 2360.0, 2338.0, 3581.0, 2051.0, 1968.0, 3345.0, 1733.0, 3039.0, 2714.0, 1389.0, 1594.0, 2642.0, 1325.0, 1364.0, 1311.0, 2853.0, 1415.0, 1403.0, 1345.0, 1238.0, 1338.0, 2444.0, 1351.0, 1269.0, 6077.6376953125, 2050.5341796875, 1593.485595703125, 1414.3048095703125, 1402.365234375, 1350.66845703125, 803.8912963867188, 810.5969848632812, 788.3973999023438, 766.4798583984375, 702.1530151367188, 702.2011108398438, 649.4896850585938, 628.9931030273438, 619.2138671875, 575.6196899414062, 535.4554443359375, 506.8262634277344, 495.228515625, 434.0416564941406, 429.7288513183594, 393.0025634765625, 351.294677734375, 356.7478332519531, 336.3872375488281, 320.7394104003906, 316.61895751953125, 316.43267822265625, 301.7301330566406, 300.69110107421875, 499.11767578125, 500.5362548828125, 991.772705078125, 574.9628295898438, 569.0897827148438, 1575.7640380859375, 1190.7568359375, 513.8673706054688, 564.053466796875, 575.9725952148438, 902.0592041015625, 666.4379272460938, 1061.02734375, 731.658447265625, 706.3803100585938, 776.9239501953125, 662.0498657226562, 584.1708374023438, 2338.101806640625, 1967.5950927734375, 1344.338623046875, 1338.184326171875, 1268.27587890625, 1011.6633911132812, 1731.38818359375, 612.9998168945312, 594.568359375, 572.0286865234375, 565.2387084960938, 545.318359375, 543.3240356445312, 545.63720703125, 508.4407958984375, 487.5102233886719, 463.9232482910156, 445.4333190917969, 428.6571044921875, 418.65142822265625, 419.7822570800781, 417.44586181640625, 407.4806213378906, 402.3387756347656, 387.77838134765625, 396.07904052734375, 380.4788818359375, 355.9372863769531, 356.2610168457031, 344.098876953125, 702.9564819335938, 379.60504150390625, 786.008056640625, 626.9859008789062, 529.7243041992188, 2906.581298828125, 2052.44482421875, 7081.6015625, 1206.11181640625, 1886.3328857421875, 1505.410888671875, 1662.7288818359375, 768.1243286132812, 1075.91748046875, 1311.517822265625, 1514.037353515625, 1427.273193359375, 973.1710205078125, 943.9678344726562, 1228.88134765625, 693.4970092773438, 1337.8037109375, 1075.5467529296875, 694.7410888671875, 830.9562377929688, 636.9519653320312, 651.8700561523438, 5535.7216796875, 3925.46484375, 2504.44580078125, 2359.9345703125, 1363.6641845703125, 1310.286376953125, 1237.82666015625, 1167.637451171875, 928.2704467773438, 886.7036743164062, 710.1030883789062, 628.320068359375, 575.575439453125, 563.6619262695312, 548.4783935546875, 544.0115966796875, 546.0946044921875, 504.6491394042969, 501.5177917480469, 486.61322021484375, 490.45257568359375, 503.5521545410156, 454.9296875, 434.2041015625, 429.74005126953125, 428.98272705078125, 465.1589050292969, 421.79730224609375, 424.2373352050781, 415.4779052734375, 422.0811767578125, 1018.5907592773438, 590.0991821289062, 1761.8214111328125, 2289.29345703125, 1346.39599609375, 1113.0921630859375, 1368.8853759765625, 617.350830078125, 716.4795532226562, 755.3909912109375, 682.3480224609375, 598.504150390625, 609.8797607421875, 627.9459228515625, 674.4934692382812, 662.158935546875, 3236.935302734375, 1388.6876220703125, 1325.233642578125, 1108.6309814453125, 985.5994262695312, 981.1845092773438, 977.8139038085938, 768.558349609375, 623.92236328125, 540.7149047851562, 525.4947509765625, 519.0524291992188, 479.5922546386719, 471.29779052734375, 423.22198486328125, 407.81414794921875, 391.39349365234375, 383.1961364746094, 356.5600891113281, 328.2990417480469, 324.709228515625, 317.4813232421875, 318.7308349609375, 320.23150634765625, 314.5645446777344, 312.72344970703125, 298.7467346191406, 302.7375793457031, 318.3066101074219, 346.1589050292969, 796.3516845703125, 1830.7958984375, 1611.784423828125, 3970.960205078125, 709.37646484375, 1132.7442626953125, 771.605224609375, 1231.4381103515625, 989.9494018554688, 1246.70068359375, 741.7333984375, 665.7291870117188, 900.344482421875, 648.3058471679688, 524.6200561523438, 656.762451171875, 642.3030395507812, 568.5200805664062], \"Term\": [\"women\", \"trump\", \"people\", \"men\", \"quora\", \"girls\", \"sex\", \"world\", \"white\", \"liberals\", \"chinese\", \"muslims\", \"country\", \"india\", \"americans\", \"questions\", \"president\", \"black\", \"god\", \"gay\", \"man\", \"us\", \"obama\", \"donald\", \"china\", \"woman\", \"countries\", \"indians\", \"democrats\", \"racist\", \"trump\", \"liberals\", \"president\", \"obama\", \"donald\", \"democrats\", \"gun\", \"left\", \"hillary\", \"media\", \"conservatives\", \"supporters\", \"liberal\", \"clinton\", \"republicans\", \"party\", \"immigrants\", \"illegal\", \"political\", \"guns\", \"everything\", \"korea\", \"election\", \"vote\", \"conservative\", \"russians\", \"putin\", \"crimes\", \"blame\", \"far\", \"russian\", \"control\", \"right\", \"russia\", \"realize\", \"would\", \"us\", \"keep\", \"support\", \"anti\", \"think\", \"america\", \"people\", \"many\", \"get\", \"like\", \"americans\", \"american\", \"world\", \"chinese\", \"china\", \"countries\", \"racist\", \"israel\", \"country\", \"poor\", \"african\", \"towards\", \"race\", \"europe\", \"europeans\", \"earth\", \"blacks\", \"population\", \"east\", \"whites\", \"west\", \"asians\", \"islamic\", \"terrorists\", \"european\", \"pakistani\", \"terrorist\", \"especially\", \"police\", \"palestinians\", \"iran\", \"arabs\", \"western\", \"living\", \"south\", \"jewish\", \"japanese\", \"white\", \"americans\", \"people\", \"jews\", \"black\", \"hate\", \"us\", \"usa\", \"america\", \"indians\", \"muslims\", \"india\", \"american\", \"muslim\", \"think\", \"north\", \"like\", \"many\", \"pakistan\", \"much\", \"non\", \"indian\", \"women\", \"men\", \"girls\", \"sex\", \"gay\", \"man\", \"woman\", \"old\", \"girl\", \"guys\", \"rape\", \"child\", \"sister\", \"male\", \"sexual\", \"guy\", \"okay\", \"mother\", \"feminists\", \"boys\", \"female\", \"dog\", \"penis\", \"mom\", \"daughter\", \"marry\", \"kids\", \"son\", \"parents\", \"fuck\", \"gender\", \"year\", \"big\", \"get\", \"like\", \"indian\", \"want\", \"would\", \"love\", \"feel\", \"black\", \"make\", \"children\", \"good\", \"one\", \"white\", \"think\", \"quora\", \"questions\", \"god\", \"christians\", \"modi\", \"hindus\", \"stupid\", \"atheists\", \"question\", \"fake\", \"bjp\", \"hindu\", \"religious\", \"answer\", \"answers\", \"jesus\", \"asking\", \"news\", \"tamil\", \"language\", \"english\", \"atheist\", \"bible\", \"dumb\", \"speak\", \"hell\", \"hindi\", \"superior\", \"body\", \"might\", \"religion\", \"muslims\", \"india\", \"people\", \"islam\", \"indians\", \"believe\", \"many\", \"indian\", \"like\", \"muslim\", \"know\", \"think\", \"even\", \"kill\", \"hate\", \"would\", \"one\"], \"Total\": [5536.0, 6078.0, 12113.0, 3926.0, 3237.0, 2505.0, 2360.0, 2338.0, 3581.0, 2051.0, 1968.0, 3345.0, 1733.0, 3039.0, 2714.0, 1389.0, 1594.0, 2642.0, 1325.0, 1364.0, 1311.0, 2853.0, 1415.0, 1403.0, 1345.0, 1238.0, 1338.0, 2444.0, 1351.0, 1269.0, 6078.36474609375, 2051.268798828125, 1594.214111328125, 1415.0321044921875, 1403.0897216796875, 1351.3944091796875, 804.6183471679688, 811.3369750976562, 789.1192626953125, 767.2200317382812, 702.8817138671875, 702.93603515625, 650.2279052734375, 629.715576171875, 619.9400024414062, 576.3504638671875, 536.1987915039062, 507.57220458984375, 495.9666748046875, 434.7754821777344, 430.4906005859375, 393.7677001953125, 352.0172424316406, 357.482421875, 337.12054443359375, 321.47943115234375, 317.3515319824219, 317.19927978515625, 302.4744873046875, 301.4388427734375, 526.6043090820312, 561.7555541992188, 1328.4654541015625, 724.9315185546875, 750.8106689453125, 4052.38623046875, 2853.98046875, 684.6565551757812, 828.7635498046875, 929.2392578125, 3693.44384765625, 1742.84521484375, 12113.837890625, 3387.36279296875, 2959.2294921875, 5650.7216796875, 2714.98486328125, 1776.091064453125, 2338.843017578125, 1968.3272705078125, 1345.0701904296875, 1338.9129638671875, 1269.015625, 1012.391845703125, 1733.135986328125, 613.7442626953125, 595.2965698242188, 572.782958984375, 565.9898681640625, 546.0441284179688, 544.0557250976562, 546.37744140625, 509.16943359375, 488.24658203125, 464.64898681640625, 446.1615905761719, 429.39300537109375, 419.3773498535156, 420.5150146484375, 418.17755126953125, 408.209716796875, 403.08709716796875, 388.513671875, 396.8337707519531, 381.2239074707031, 356.66522216796875, 357.00262451171875, 344.822998046875, 706.2723999023438, 380.4040222167969, 796.9534301757812, 638.117431640625, 537.3046264648438, 3581.566650390625, 2714.98486328125, 12113.837890625, 1509.485107421875, 2642.213134765625, 2247.3544921875, 2853.98046875, 990.4749755859375, 1742.84521484375, 2444.74462890625, 3345.31689453125, 3039.54345703125, 1776.091064453125, 1951.277099609375, 3693.44384765625, 967.10693359375, 5650.7216796875, 3387.36279296875, 1013.8775634765625, 1905.607421875, 1023.5613403320312, 2988.458984375, 5536.44921875, 3926.189208984375, 2505.1689453125, 2360.65576171875, 1364.398193359375, 1311.0235595703125, 1238.5511474609375, 1168.428466796875, 928.9920043945312, 887.4302978515625, 710.8436279296875, 629.0635375976562, 576.2911376953125, 564.3900756835938, 549.2068481445312, 544.737548828125, 546.8552856445312, 505.3752136230469, 502.25537109375, 487.3348693847656, 491.1812438964844, 504.3147888183594, 455.6492004394531, 434.9188232421875, 430.46173095703125, 429.7081604003906, 465.95501708984375, 422.5206298828125, 424.9738464355469, 416.2115783691406, 422.8297424316406, 1066.7230224609375, 659.7426147460938, 2959.2294921875, 5650.7216796875, 2988.458984375, 2291.685302734375, 4052.38623046875, 984.2098999023438, 1557.9794921875, 2642.213134765625, 1786.79296875, 1134.641845703125, 1324.857421875, 1839.30615234375, 3581.566650390625, 3693.44384765625, 3237.676025390625, 1389.4091796875, 1325.959716796875, 1109.358154296875, 986.3214111328125, 981.9047241210938, 978.5473022460938, 769.277587890625, 624.6819458007812, 541.4569091796875, 526.2166748046875, 519.783935546875, 480.3285217285156, 472.023193359375, 423.94329833984375, 408.5419921875, 392.13726806640625, 383.936279296875, 357.28759765625, 329.0279846191406, 325.4372253417969, 318.20751953125, 319.45989990234375, 320.9727478027344, 315.2981872558594, 313.45831298828125, 299.4658203125, 303.48406982421875, 319.0919494628906, 347.02496337890625, 799.2946166992188, 3345.31689453125, 3039.54345703125, 12113.837890625, 1074.548095703125, 2444.74462890625, 1443.618896484375, 3387.36279296875, 2988.458984375, 5650.7216796875, 1951.277099609375, 1578.9306640625, 3693.44384765625, 1639.4287109375, 945.3306274414062, 2247.3544921875, 4052.38623046875, 1839.30615234375], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2934999465942383, 1.2932000160217285, 1.2930999994277954, 1.2930999994277954, 1.2930999994277954, 1.2930999994277954, 1.2927000522613525, 1.2927000522613525, 1.2927000522613525, 1.2926000356674194, 1.2926000356674194, 1.2925000190734863, 1.2925000190734863, 1.2924000024795532, 1.2924000024795532, 1.2922999858856201, 1.292199969291687, 1.292099952697754, 1.292099952697754, 1.2919000387191772, 1.2918000221252441, 1.291599988937378, 1.2914999723434448, 1.2914999723434448, 1.2913999557495117, 1.2913000583648682, 1.2913000583648682, 1.291200041770935, 1.291100025177002, 1.291100025177002, 1.2400000095367432, 1.1782000064849854, 1.0012999773025513, 1.0618000030517578, 1.0164999961853027, 0.3490000069141388, 0.4194999933242798, 1.006600022315979, 0.9088000059127808, 0.8152999877929688, -0.11599999666213989, 0.33230000734329224, -1.1414999961853027, -0.23890000581741333, -0.1388999968767166, -0.6905999779701233, -0.11760000139474869, 0.18160000443458557, 1.333299994468689, 1.3331999778747559, 1.3329999446868896, 1.3329999446868896, 1.3329999446868896, 1.332900047302246, 1.3325999975204468, 1.3323999643325806, 1.3323999643325806, 1.3322999477386475, 1.3322999477386475, 1.3322999477386475, 1.332200050354004, 1.332200050354004, 1.332200050354004, 1.3321000337600708, 1.3320000171661377, 1.3320000171661377, 1.3319000005722046, 1.3319000005722046, 1.3317999839782715, 1.3317999839782715, 1.3317999839782715, 1.3316999673843384, 1.3316999673843384, 1.3316999673843384, 1.3315999507904053, 1.3315000534057617, 1.3315000534057617, 1.3315000534057617, 1.3288999795913696, 1.3315000534057617, 1.3198000192642212, 1.315999984741211, 1.3193999528884888, 1.1247999668121338, 1.0537999868392944, 0.7967000007629395, 1.1092000007629395, 0.9965999722480774, 0.9329000115394592, 0.7932999730110168, 1.0793999433517456, 0.8511999845504761, 0.7107999920845032, 0.5407999753952026, 0.5776000022888184, 0.7319999933242798, 0.6074000000953674, 0.23309999704360962, 1.0010000467300415, -0.10719999670982361, 0.18639999628067017, 0.9556000232696533, 0.503600001335144, 0.8592000007629395, -0.1890999972820282, 1.4414000511169434, 1.4413000345230103, 1.4412000179290771, 1.4412000179290771, 1.440999984741211, 1.440999984741211, 1.4408999681472778, 1.4407999515533447, 1.4407000541687012, 1.4407000541687012, 1.440500020980835, 1.4402999877929688, 1.4402999877929688, 1.4401999711990356, 1.4401999711990356, 1.4401999711990356, 1.4400999546051025, 1.4400999546051025, 1.4400999546051025, 1.440000057220459, 1.440000057220459, 1.440000057220459, 1.4399000406265259, 1.4399000406265259, 1.4398000240325928, 1.4398000240325928, 1.4398000240325928, 1.4398000240325928, 1.4398000240325928, 1.4398000240325928, 1.4397000074386597, 1.395400047302246, 1.3300000429153442, 0.9229000210762024, 0.5379999876022339, 0.6442000269889832, 0.7193999886512756, 0.3562000095844269, 0.9750999808311462, 0.6646999716758728, 0.18940000236034393, 0.4788999855518341, 0.8019000291824341, 0.6657000184059143, 0.3668000102043152, -0.2281000018119812, -0.27730000019073486, 1.488700032234192, 1.4883999824523926, 1.4883999824523926, 1.4882999658584595, 1.4881999492645264, 1.4881999492645264, 1.4881999492645264, 1.4880000352859497, 1.4876999855041504, 1.4874999523162842, 1.4874999523162842, 1.4874999523162842, 1.4874000549316406, 1.4874000549316406, 1.4872000217437744, 1.4871000051498413, 1.4869999885559082, 1.4869999885559082, 1.486899971961975, 1.4867000579833984, 1.4867000579833984, 1.4866000413894653, 1.4866000413894653, 1.4866000413894653, 1.4866000413894653, 1.4866000413894653, 1.4865000247955322, 1.4865000247955322, 1.4864000082015991, 1.4864000082015991, 1.485200047492981, 0.8860999941825867, 0.8544999957084656, 0.3736000061035156, 1.0736000537872314, 0.7196000218391418, 0.862500011920929, 0.47699999809265137, 0.3840999901294708, -0.02239999920129776, 0.5217000246047974, 0.6252999901771545, 0.07739999890327454, 0.5612000226974487, 0.9000999927520752, 0.25870001316070557, -0.3531000018119812, 0.3147999942302704], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.487600088119507, -4.574100017547607, -4.826200008392334, -4.945499897003174, -4.953999996185303, -4.991600036621094, -5.510499954223633, -5.502200126647949, -5.529900074005127, -5.55810022354126, -5.6458001136779785, -5.645699977874756, -5.723700046539307, -5.755799770355225, -5.771500110626221, -5.8445000648498535, -5.916800022125244, -5.971799850463867, -5.994900226593018, -6.126800060272217, -6.1367998123168945, -6.226099967956543, -6.3383002281188965, -6.32289981842041, -6.381700038909912, -6.429299831390381, -6.442200183868408, -6.442800045013428, -6.4903998374938965, -6.493800163269043, -5.987100124359131, -5.9842000007629395, -5.3003997802734375, -5.845600128173828, -5.855899810791016, -4.837399959564209, -5.117599964141846, -5.958000183105469, -5.864799976348877, -5.843900203704834, -5.395199775695801, -5.697999954223633, -5.232900142669678, -5.604599952697754, -5.639800071716309, -5.544600009918213, -5.704599857330322, -5.829699993133545, -4.4028000831604, -4.575399875640869, -4.956299781799316, -4.960899829864502, -5.014500141143799, -5.240600109100342, -4.703199863433838, -5.741600036621094, -5.77209997177124, -5.810699939727783, -5.822700023651123, -5.85860013961792, -5.862199783325195, -5.857999801635742, -5.928599834442139, -5.970600128173828, -6.020199775695801, -6.0609002113342285, -6.099299907684326, -6.122900009155273, -6.120200157165527, -6.125800132751465, -6.149899959564209, -6.162600040435791, -6.19950008392334, -6.178299903869629, -6.218500137329102, -6.285200119018555, -6.284299850463867, -6.318999767303467, -5.604599952697754, -6.220799922943115, -5.493000030517578, -5.718999862670898, -5.887599945068359, -4.185200214385986, -4.533100128173828, -3.2946999073028564, -5.064799785614014, -4.617499828338623, -4.843100070953369, -4.74370002746582, -5.515999794006348, -5.178999900817871, -4.980999946594238, -4.837399959564209, -4.896399974822998, -5.279399871826172, -5.309800148010254, -5.04610013961792, -5.618199825286865, -4.961100101470947, -5.179299831390381, -5.616399765014648, -5.437300205230713, -5.703199863433838, -5.680099964141846, -3.433000087738037, -3.776700019836426, -4.226200103759766, -4.285600185394287, -4.834099769592285, -4.874000072479248, -4.9309000968933105, -4.989200115203857, -5.218699932098389, -5.264500141143799, -5.486599922180176, -5.60890007019043, -5.696599960327148, -5.71750020980835, -5.744800090789795, -5.752999782562256, -5.749199867248535, -5.828100204467773, -5.8343000411987305, -5.864500045776367, -5.8566999435424805, -5.8302998542785645, -5.93179988861084, -5.978499889373779, -5.988800048828125, -5.990600109100342, -5.909599781036377, -6.007500171661377, -6.001699924468994, -6.022600173950195, -6.006800174713135, -5.125800132751465, -5.6717000007629395, -4.577899932861328, -4.315999984741211, -4.846799850463867, -5.037099838256836, -4.8302001953125, -5.6265997886657715, -5.47760009765625, -5.424799919128418, -5.526400089263916, -5.657599925994873, -5.638700008392334, -5.609499931335449, -5.538000106811523, -5.55649995803833, -3.9221999645233154, -4.768499851226807, -4.815299987792969, -4.99370002746582, -5.111299991607666, -5.115799903869629, -5.11929988861084, -5.360099792480469, -5.568600177764893, -5.711699962615967, -5.740300178527832, -5.752600193023682, -5.831699848175049, -5.849100112915039, -5.956699848175049, -5.993800163269043, -6.034900188446045, -6.056000232696533, -6.1280999183654785, -6.210700035095215, -6.221700191497803, -6.244200229644775, -6.240200042724609, -6.235599994659424, -6.253399848937988, -6.259300231933594, -6.304999828338623, -6.2916998863220215, -6.241600036621094, -6.157700061798096, -5.3246002197265625, -4.492099761962891, -4.619500160217285, -3.7177999019622803, -5.440199851989746, -4.9721999168396, -5.356100082397461, -4.888700008392334, -5.106900215148926, -4.876299858093262, -5.395599842071533, -5.503699779510498, -5.2017998695373535, -5.530200004577637, -5.7418999671936035, -5.517300128936768, -5.5395002365112305, -5.661600112915039]}, \"token.table\": {\"Topic\": [2, 1, 2, 1, 2, 3, 1, 2, 4, 4, 1, 4, 2, 2, 4, 4, 4, 1, 2, 4, 4, 2, 3, 4, 2, 3, 2, 1, 4, 3, 3, 1, 2, 3, 4, 2, 2, 4, 1, 1, 1, 1, 2, 2, 1, 2, 1, 3, 1, 3, 1, 4, 2, 2, 1, 4, 2, 2, 2, 2, 1, 2, 3, 4, 1, 4, 1, 1, 2, 3, 4, 3, 3, 3, 3, 3, 1, 2, 3, 4, 3, 3, 4, 1, 2, 3, 4, 1, 1, 3, 3, 1, 2, 4, 4, 1, 4, 4, 4, 1, 1, 2, 4, 2, 3, 4, 2, 4, 2, 2, 4, 2, 2, 2, 3, 4, 1, 2, 2, 4, 1, 2, 4, 3, 2, 4, 1, 2, 3, 4, 1, 4, 1, 1, 1, 1, 2, 3, 4, 2, 1, 2, 3, 4, 1, 2, 3, 4, 3, 3, 1, 2, 3, 4, 3, 1, 3, 4, 4, 3, 3, 1, 2, 3, 4, 2, 3, 4, 2, 4, 4, 2, 4, 1, 2, 4, 1, 3, 3, 1, 2, 3, 4, 2, 4, 2, 2, 3, 1, 3, 1, 2, 4, 2, 1, 2, 2, 1, 1, 4, 4, 4, 2, 2, 3, 1, 2, 2, 4, 4, 1, 1, 2, 3, 4, 1, 2, 1, 2, 1, 3, 3, 3, 3, 1, 2, 4, 4, 4, 4, 1, 2, 4, 1, 4, 2, 2, 1, 2, 3, 4, 2, 1, 1, 2, 1, 2, 1, 1, 2, 3, 4, 2, 2, 3, 2, 3, 2, 3, 3, 2, 1, 2, 3, 4, 2, 3], \"Freq\": [0.9995018243789673, 0.38213375210762024, 0.6173812747001648, 0.32881197333335876, 0.5478322505950928, 0.12330448627471924, 0.24383193254470825, 0.7558053135871887, 0.9978322982788086, 0.9977749586105347, 0.619861900806427, 0.3798806369304657, 0.997613251209259, 0.9991002082824707, 0.9970998167991638, 0.9962052702903748, 0.9996391534805298, 0.31033122539520264, 0.15516561269760132, 0.5347671508789062, 0.99856036901474, 0.10458624362945557, 0.8942881226539612, 0.9976878762245178, 0.71379554271698, 0.2857452929019928, 0.9977032542228699, 0.9984313249588013, 0.9965779185295105, 0.9993128776550293, 0.998309314250946, 0.29260334372520447, 0.17802974581718445, 0.5279198884963989, 0.0017626708140596747, 0.9992043375968933, 0.9998337030410767, 0.9996771812438965, 0.9988636374473572, 0.9966761469841003, 0.9987455606460571, 0.8918470144271851, 0.10858815908432007, 0.9993181228637695, 0.0005769887939095497, 0.9987675547599792, 0.9962191581726074, 0.9989273548126221, 0.9997081756591797, 0.9993758201599121, 0.9992233514785767, 0.9969694018363953, 0.9993091821670532, 0.9986032843589783, 0.9971102476119995, 0.9986565113067627, 0.9978989362716675, 0.9980878233909607, 0.9970365166664124, 0.9980595111846924, 0.2647263705730438, 0.1415127068758011, 0.19884975254535675, 0.39525964856147766, 0.9988603591918945, 0.9991561770439148, 0.9985441565513611, 0.12772953510284424, 0.2458312213420868, 0.4595696032047272, 0.16688281297683716, 0.9975950717926025, 0.9994915723800659, 0.9970890283584595, 0.9997081756591797, 0.9980376362800598, 0.23857562243938446, 0.09630885720252991, 0.5954252481460571, 0.06961271166801453, 0.9989321827888489, 0.9995334148406982, 0.9992762207984924, 0.222665473818779, 0.10718134790658951, 0.4604268968105316, 0.20983390510082245, 0.9992315173149109, 0.9982163906097412, 0.9986460208892822, 0.9995151162147522, 0.03782225027680397, 0.6696763038635254, 0.29234373569488525, 0.9985378980636597, 0.9985816478729248, 0.9984444975852966, 0.9984918236732483, 0.999078631401062, 0.9988726377487183, 0.9977642893791199, 0.46947839856147766, 0.5303428173065186, 0.21817263960838318, 0.45039936900138855, 0.3312744200229645, 0.5366613864898682, 0.4634431004524231, 0.9971915483474731, 0.3396776616573334, 0.6598122715950012, 0.9987753033638, 0.9996129274368286, 0.986405074596405, 0.01302799116820097, 0.9986733794212341, 0.017238207161426544, 0.9825777411460876, 0.7989479303359985, 0.20073069632053375, 0.7507413625717163, 0.0014605863252654672, 0.24683909118175507, 0.9979504346847534, 0.4442889988422394, 0.555361270904541, 0.22356903553009033, 0.13426809012889862, 0.2210356742143631, 0.4218044579029083, 0.9980503916740417, 0.9968757033348083, 0.9995846748352051, 0.9981116056442261, 0.9998689889907837, 0.13750456273555756, 0.2367839217185974, 0.40508100390434265, 0.22067977488040924, 0.9989379048347473, 0.05588238686323166, 0.18898408114910126, 0.6268987655639648, 0.1280214786529541, 0.23729665577411652, 0.17181621491909027, 0.3816894292831421, 0.20875389873981476, 0.9993088841438293, 0.9992192387580872, 0.21609731018543243, 0.31765124201774597, 0.1030300036072731, 0.36340954899787903, 0.9983519911766052, 0.9984098076820374, 0.9996970891952515, 0.9970464110374451, 0.9996741414070129, 0.997887372970581, 0.9992575645446777, 0.21462972462177277, 0.4360814392566681, 0.16372732818126678, 0.1857675313949585, 0.4837857186794281, 0.13580849766731262, 0.3802637755870819, 0.4525729715824127, 0.5473322868347168, 0.9975613951683044, 0.6223369240760803, 0.3771146833896637, 0.1333875209093094, 0.7165701985359192, 0.14993171393871307, 0.9992706179618835, 0.9984359741210938, 0.9996333122253418, 0.2636863887310028, 0.08590196073055267, 0.3414331078529358, 0.30935579538345337, 0.6854870915412903, 0.31463363766670227, 0.9973030686378479, 0.9981349110603333, 0.9977084398269653, 0.9993919134140015, 0.9985752105712891, 0.08758578449487686, 0.5846206545829773, 0.32780691981315613, 0.9967895150184631, 0.9980509281158447, 0.9987873435020447, 0.9994949698448181, 0.9992384314537048, 0.9988923072814941, 0.9989083409309387, 0.9997054934501648, 0.9997912049293518, 0.9982510805130005, 0.9991996884346008, 0.9988132119178772, 0.7578474879264832, 0.24107275903224945, 0.0025022062472999096, 0.9958781003952026, 0.9993160367012024, 0.9984837174415588, 0.7467262148857117, 0.07000558078289032, 0.14151667058467865, 0.04215389862656593, 0.793178379535675, 0.2055366486310959, 0.9475805759429932, 0.051271893084049225, 0.9985086917877197, 0.9997221827507019, 0.9978025555610657, 0.9994947910308838, 0.9987677931785583, 0.001254778471775353, 0.9862558841705322, 0.012547784484922886, 0.9990542531013489, 0.9994406700134277, 0.9984049797058105, 0.6805318593978882, 0.1966785341501236, 0.12186829745769501, 0.998668372631073, 0.9991950392723083, 0.9986778497695923, 0.9971840977668762, 0.24421651661396027, 0.3327517807483673, 0.1792365163564682, 0.24367502331733704, 0.998633086681366, 0.9999399781227112, 0.4173119068145752, 0.582694947719574, 0.2241348922252655, 0.7753855586051941, 0.9986504912376404, 0.17454403638839722, 0.2530888617038727, 0.48566877841949463, 0.08683566004037857, 0.9990847706794739, 0.995366632938385, 0.00424765283241868, 0.8116559982299805, 0.18818581104278564, 0.9973964691162109, 0.9995549917221069, 0.9999188780784607, 0.9996395707130432, 0.38890665769577026, 0.11474720388650894, 0.3378256559371948, 0.15842518210411072, 0.044997621327638626, 0.9552620053291321], \"Term\": [\"african\", \"america\", \"america\", \"american\", \"american\", \"american\", \"americans\", \"americans\", \"answer\", \"answers\", \"anti\", \"anti\", \"arabs\", \"asians\", \"asking\", \"atheist\", \"atheists\", \"believe\", \"believe\", \"believe\", \"bible\", \"big\", \"big\", \"bjp\", \"black\", \"black\", \"blacks\", \"blame\", \"body\", \"boys\", \"child\", \"children\", \"children\", \"children\", \"children\", \"china\", \"chinese\", \"christians\", \"clinton\", \"conservative\", \"conservatives\", \"control\", \"control\", \"countries\", \"country\", \"country\", \"crimes\", \"daughter\", \"democrats\", \"dog\", \"donald\", \"dumb\", \"earth\", \"east\", \"election\", \"english\", \"especially\", \"europe\", \"european\", \"europeans\", \"even\", \"even\", \"even\", \"even\", \"everything\", \"fake\", \"far\", \"feel\", \"feel\", \"feel\", \"feel\", \"female\", \"feminists\", \"fuck\", \"gay\", \"gender\", \"get\", \"get\", \"get\", \"get\", \"girl\", \"girls\", \"god\", \"good\", \"good\", \"good\", \"good\", \"gun\", \"guns\", \"guy\", \"guys\", \"hate\", \"hate\", \"hate\", \"hell\", \"hillary\", \"hindi\", \"hindu\", \"hindus\", \"illegal\", \"immigrants\", \"india\", \"india\", \"indian\", \"indian\", \"indian\", \"indians\", \"indians\", \"iran\", \"islam\", \"islam\", \"islamic\", \"israel\", \"japanese\", \"japanese\", \"jesus\", \"jewish\", \"jewish\", \"jews\", \"jews\", \"keep\", \"keep\", \"keep\", \"kids\", \"kill\", \"kill\", \"know\", \"know\", \"know\", \"know\", \"korea\", \"language\", \"left\", \"liberal\", \"liberals\", \"like\", \"like\", \"like\", \"like\", \"living\", \"love\", \"love\", \"love\", \"love\", \"make\", \"make\", \"make\", \"make\", \"male\", \"man\", \"many\", \"many\", \"many\", \"many\", \"marry\", \"media\", \"men\", \"might\", \"modi\", \"mom\", \"mother\", \"much\", \"much\", \"much\", \"much\", \"muslim\", \"muslim\", \"muslim\", \"muslims\", \"muslims\", \"news\", \"non\", \"non\", \"north\", \"north\", \"north\", \"obama\", \"okay\", \"old\", \"one\", \"one\", \"one\", \"one\", \"pakistan\", \"pakistan\", \"pakistani\", \"palestinians\", \"parents\", \"party\", \"penis\", \"people\", \"people\", \"people\", \"police\", \"political\", \"poor\", \"population\", \"president\", \"putin\", \"question\", \"questions\", \"quora\", \"race\", \"racist\", \"rape\", \"realize\", \"realize\", \"religion\", \"religion\", \"religious\", \"republicans\", \"right\", \"right\", \"right\", \"right\", \"russia\", \"russia\", \"russian\", \"russian\", \"russians\", \"sex\", \"sexual\", \"sister\", \"son\", \"south\", \"south\", \"south\", \"speak\", \"stupid\", \"superior\", \"support\", \"support\", \"support\", \"supporters\", \"tamil\", \"terrorist\", \"terrorists\", \"think\", \"think\", \"think\", \"think\", \"towards\", \"trump\", \"us\", \"us\", \"usa\", \"usa\", \"vote\", \"want\", \"want\", \"want\", \"want\", \"west\", \"western\", \"western\", \"white\", \"white\", \"whites\", \"woman\", \"women\", \"world\", \"would\", \"would\", \"would\", \"would\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 2, 3]};\n\nfunction LDAvis_load_lib(url, callback){\n  var s = document.createElement('script');\n  s.src = url;\n  s.async = true;\n  s.onreadystatechange = s.onload = callback;\n  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n  document.getElementsByTagName(\"head\")[0].appendChild(s);\n}\n\nif(typeof(LDAvis) !== \"undefined\"){\n   // already loaded: just create the visualization\n   !function(LDAvis){\n       new LDAvis(\"#\" + \"ldavis_el231403994409235285614350760\", ldavis_el231403994409235285614350760_data);\n   }(LDAvis);\n}else if(typeof define === \"function\" && define.amd){\n   // require.js is available: use it to load d3/LDAvis\n   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n   require([\"d3\"], function(d3){\n      window.d3 = d3;\n      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n        new LDAvis(\"#\" + \"ldavis_el231403994409235285614350760\", ldavis_el231403994409235285614350760_data);\n      });\n    });\n}else{\n    // require.js not available: dynamically load d3 & LDAvis\n    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n                 new LDAvis(\"#\" + \"ldavis_el231403994409235285614350760\", ldavis_el231403994409235285614350760_data);\n            })\n         });\n}\n</script>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "30cb0f608e902483810c6837a2a987247d98d8e9"
      },
      "cell_type": "markdown",
      "source": "We could see 4 distincts topics: \n- topic 1 is about politic with top-3 keyword being \"Trump\", \"liberals\", \"presidents\". It's also the bigger topic;\n- topic 2 is about race and nationality with keywords \"white\", \"black\", \"people\";\n- topic 3 is about gender and sex, \"women\", \"men\", \"gay\";\n- topic 4 is about religion it seems, with keywords \"christians\", \"muslims\".\n\nThis topics could be use cause they rejoign the subjects given by Quora as sensible. This topic could be used as a variable \nto characteristic insincere question and be used for machine learning. "
    },
    {
      "metadata": {
        "_uuid": "e0c0ba1a4fbb143f38e032196ff0147a9ac058bd"
      },
      "cell_type": "markdown",
      "source": "---"
    },
    {
      "metadata": {
        "_uuid": "02c09fa4cd105a1263758543f2832812f8693d15"
      },
      "cell_type": "markdown",
      "source": "#### Quick machine learning model\n\nThis kernel is mostly center around the topic modeling but let's try a quick and simple model just to see how it works. This model doesn't use the topic modeling, which maybe could help to improve the final score. "
    },
    {
      "metadata": {
        "_uuid": "2122e9767e084ff68d25ccaf750cad0fa897304b",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split",
      "execution_count": 51,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2460705db26e3cf4e8437f1b0acba9c40efe52ce"
      },
      "cell_type": "markdown",
      "source": "Train_test_split is not the most precise method of validation but I just want to quickly test the model as a first try. "
    },
    {
      "metadata": {
        "_uuid": "f750ac8625dc7cc006d93b9c1227f580ac2fd0b8",
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 52,
          "data": {
            "text/plain": "((979591,), (979591,), (326531,), (326531,))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "32ae03a5cfcbbe2394bc4b2a830afa0ba361e28f"
      },
      "cell_type": "markdown",
      "source": "Now i have my training and testing sample for train my model. I will do a pipeline with a transformer, to turn the text value to vectors and an estimator, to predict. "
    },
    {
      "metadata": {
        "_uuid": "6bb71a93c19a41664841da68341c92f894dbc9d4",
        "trusted": true
      },
      "cell_type": "code",
      "source": "tfidv = TfidfVectorizer(lowercase=True, stop_words='english')\nmultinomialnb = MultinomialNB()\npipe = make_pipeline(tfidv, multinomialnb)\npipe",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 53,
          "data": {
            "text/plain": "Pipeline(memory=None,\n     steps=[('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth...   vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "610c9f39785f635a27f08300c6fc1a8758517dc1",
        "trusted": true
      },
      "cell_type": "code",
      "source": "pipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\nprint(classification_report(y_test, y_pred))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7ca85c39d9f5b42ee1d1008e1b713e3811a0d0f5"
      },
      "cell_type": "markdown",
      "source": "**As expected for a naive model and without any ponderation on a disbalance datasets, the F1 score is quite good for 0 and really bad for 1.**\n\n**Enginere featuring and ponderation could let us have a better score. **"
    },
    {
      "metadata": {
        "_uuid": "58c77e7f809415752739c93a1a16587e493ba80f",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}